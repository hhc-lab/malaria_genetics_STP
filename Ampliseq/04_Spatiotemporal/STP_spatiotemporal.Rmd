---
title: "STP_spatiotemporal"
author: "Angie"
date: "2023-11-07"
output: 
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
---

# Chapter 7 - Spatial-temporal analysis of moire results

**Load libraries and working directory**
```{r load libs, echo=FALSE, warning = FALSE, message= FALSE}

library(moire)
library(dcifer)
library(dplyr)
library(magrittr)
library(ggplot2)
library(reshape2)
library(tidyr)
library(waldo)
library(tidyverse)
library(stringr)
library(tools)
library(purrr)
library(parallel)
library(data.table)
library(ggalt)
library(vctrs)
library(plotly)
library(cowplot)
library(igraph)
library(descriptr)
library(Polychrome)
library(trelliscopejs)
library(crosstalk)
library(shiny)
library(htmltools)
library(htmlwidgets)
library(viridis)
library(geojsonio)
library(geojsonsf)
library(sf)
library(ggthemes)
library(rcartocolor)
library(car)
library(gridExtra)
library(ggrepel)
library(readxl)
library(scales)
library(ggnewscale)
library(dunn.test)
library(ggpubr)


setwd("C:/Users/User1/SynologyDrive/UCSF work/STP data/ParagonV4") # Change it to your dir path
```


**Incidence Rate**
```{r IR, echo=FALSE, warning = FALSE, message= FALSE}

# Input data
IR <- read.csv("C:/Users/User1/SynologyDrive/UCSF work/STP data/ParagonV4/combine_list/IR_month_district.csv", header = T)
pop <- read.csv("C:/Users/User1/SynologyDrive/UCSF work/STP data/ParagonV4/combine_list/new_year_pop.csv", header = T)

# Plot IR per district per month (Calendar year)
IR %>% 
  ggplot(aes(x = Month, y = IR*100)) +
  geom_line(size = .5) +
  scale_x_continuous(breaks = seq(1, 12, 1)) +
  facet_grid(District ~ Year) +
  ylab("IR %")

### IR by NEW year groups
IR %<>%
  mutate(area = ifelse(District == "AG", "Capital", "Others")) %>%
  mutate(new_year = case_when(
    (Year == 2010 & Month >= 1 & Month <= 8) ~ "2010",
    (Year == 2010 & Month >= 9) | (Year == 2011 & Month <= 8) ~ "2011",
    (Year == 2011 & Month >= 9) | (Year == 2012 & Month <= 8) ~ "2012",
    (Year == 2012 & Month >= 9) | (Year == 2013 & Month <= 8) ~ "2013",
    (Year == 2013 & Month >= 9) | (Year == 2014 & Month <= 8) ~ "2014",
    (Year == 2014 & Month >= 9) | (Year == 2015 & Month <= 8) ~ "2015",
    (Year == 2015 & Month >= 9) | (Year == 2016 & Month <= 8) ~ "2016",
  ))

### Population estimates
pop <- reshape(data = pop,
               idvar= "Year",
               varying = 3:6, #We need to specify here the columns to be reshaped
               sep= "_",
               timevar= "area",
               times = c("Capital", "Others"),
               new.row.names= 1:10000,
               direction = "long")
pop$Year <- as.character(pop$Year)

### Annual IRalence by area
# Original - sum up cases
IR_case <- IR %>%
  group_by(Year, area) %>%
  summarize(case = sum(case1))
IR_case$Year <- as.character(IR_case$Year)

# New - sum up cases
IR_new_case <- IR %>%
  group_by(new_year, area) %>%
  summarize(case_new = sum(case1)) %>%
  rename(Year = new_year)

# Merge and calculate new IR
IR_merge <- inner_join(IR_case, IR_new_case)
IR_merge <- inner_join(IR_merge, pop)
IR_merge %<>% rename(New_pop = New, Ori_pop = Original)
IR_merge %<>%
  mutate(
    ori_IR_perc = case/Ori_pop *100,
    new_IR_perc = case_new/New_pop *100)

# Plot nationwide IR by new year groups
IR_new_year <- IR_merge %>%
  group_by(Year) %>%
  summarize(annual_case = sum(case_new), annual_pop = sum(New_pop)) %>%
  mutate(IR = annual_case/annual_pop)

IR_new_year %>%
  ggplot() +
  geom_point(aes(x = Year, y = IR *100)) +
  geom_line(aes(x = Year, y = IR * 100, group = 1)) +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8)) +
  ylab("Incidence %")

# Plot original & new IRalence
IR_merge %>% 
  ggplot(aes(group = area)) +
  geom_line(aes(x = Year, y = ori_IR_perc, color = "Original")) + 
  geom_line(aes(x = Year, y = new_IR_perc, color = "New")) +
  facet_wrap(~area) +
  labs(color = "IR") +
  ylab("Incidence %")

#write.csv(IR_merge, "./combine_list/IR_new.csv", row.names = F)
  
```


**Rearrange new year groups**
```{r assign new year, echo=FALSE, warning = FALSE, message= FALSE}

# Redefine year groups by transmission season
moire_merge <- read.csv("C:/Users/User1/SynologyDrive/UCSF work/STP data/ParagonV4/combine_list/moire_merge.csv", header = T)

new_meta <- moire_merge %>% filter(Year != 2005)
new_meta %<>%
mutate(new_year = case_when(
    between(Onset, as.Date("2010/3/1"), as.Date("2010/8/31")) ~ "2010",
    between(Onset, as.Date("2010/9/1"), as.Date("2011/8/31")) ~ "2011",
    between(Onset, as.Date("2011/9/1"), as.Date("2012/8/31")) ~ "2012",
    between(Onset, as.Date("2012/9/1"), as.Date("2013/8/31")) ~ "2013",
    between(Onset, as.Date("2013/9/1"), as.Date("2014/8/31")) ~ "2014",
    between(Onset, as.Date("2014/9/1"), as.Date("2015/8/31")) ~ "2015",
    between(Onset, as.Date("2015/9/1"), as.Date("2016/10/31")) ~ "2016",
    # Add more cases for other years as needed
    TRUE ~ "Other" )
) %<>%
mutate(area = ifelse(District == "AG", "Capital", "Others"))


# Sample distribution after year rearrangement
sample_size_dist_new <- new_meta %>% group_by(new_year, area) %>% count()  

new_meta %>%
  ggplot(aes(x = Month, fill = area)) + 
  geom_bar(stat="Count", width=1, alpha=.7) +
  geom_vline(aes(xintercept = 8), linetype = "dashed") +
  facet_wrap(~new_year) +
  ggtitle("Spatial-temporal distribution") +
  scale_x_continuous(breaks=1:12) +
  theme_minimal() +
  theme(panel.grid.minor = element_blank())

new_meta %>%
  ggplot(aes(x = Month, fill = District)) + 
  geom_bar(stat="Count", width=1, alpha=.7) +
  geom_vline(aes(xintercept = 8), linetype = "dashed") +
  facet_wrap(~new_year) +
  ggtitle("Spatial-temporal distribution") +
  scale_x_continuous(breaks=1:12) +
  theme_minimal() +
  theme(panel.grid.minor = element_blank())

# new_meta
District_new_meta <- new_meta %>% 
  group_by(District, Year, Month) %>%
  summarize(Count=n())

dis = c("AG", "LO", "MZ", "CT", "LE", "PR")
colors = c("red","blue","green","yellow", "purple", "grey")

District_new_meta %>%
  ggplot(aes(x = Month, y = Count, fill = factor(District, levels=dis))) + 
  geom_bar(width = 1, alpha = 0.6, stat = "identity") +
  geom_vline(aes(xintercept = 9), linetype = "dashed") +
  facet_wrap(~ Year) +
  ggtitle("Sequenced cases") +
  scale_x_continuous(breaks=1:12) +
  scale_fill_manual(name = "District", values = colors) +
  theme_minimal() +
  theme(panel.grid.minor = element_blank())

# HAM
HAM <- read.csv("C:/Users/User1/SynologyDrive/UCSF work/STP data/ParagonV4/combine_list/HAM_7482_complete.csv")
District_HAM <- HAM %>% 
  group_by(District, Year, Month) %>%
  summarize(Count=n())


dis = c("AG", "LO", "MZ", "CT", "LE", "PR", "CU")
colors = c("red","blue","green","yellow", "purple", "grey", "pink")

District_HAM %>%
  ggplot(aes(x = Month, y = Count, fill = factor(District, levels=dis))) + 
  geom_bar(width = 1, alpha = 0.6, stat = "identity") +
  geom_vline(aes(xintercept = 9), linetype = "dashed") +
  facet_wrap(~ Year) +
  ggtitle("HAM Reported cases") +
  scale_x_continuous(breaks=1:12) +
  scale_y_continuous(breaks=seq(0,350,50)) +
  scale_fill_manual(name = "District", values = colors) +
  theme_minimal() +
  theme(panel.grid.minor = element_blank())


```


**Plot MOI, eMOI by new year groups**
```{r moire by new year, echo=FALSE, warning = FALSE, message= FALSE}

# Calculate annual average of MOI mean
se <- function(data) {
  sd <- sd(data)
  sample_size <- length(data)
  standard_error <- sd / sqrt(sample_size)
  
  return(standard_error)
}

# Calculate annual average of MOI mean
moi_dist_new <- new_meta %>%
  group_by(new_year, area) %>%
  summarize(N_MOI = n(),
            mean_MOI = mean(post_coi_mean),
            se_MOI = se(post_coi_mean),
            upper_MOI = mean_MOI + se_MOI,
            lower_MOI = mean_MOI - se_MOI)

# Calculate annual average of eMOI mean
emoi_dist_new <- new_meta %>%
  group_by(new_year, area) %>%
  summarize(N_eMOI = n(),
            mean_eMOI = mean(post_effective_coi_mean),
            se_eMOI = se(post_effective_coi_mean),
            upper_eMOI = mean_eMOI + se_eMOI,
            lower_eMOI = mean_eMOI - se_eMOI)

#### Combine MOI, eMOI, rw and make combined plot
joined_df_new <- inner_join(moi_dist_new, emoi_dist_new)
joined_df_new$IR = IR_merge$new_IR_perc
joined_df_new %<>% mutate (IRm_MOI = IR*mean_MOI,
                          IRm_eMOI = IR*mean_eMOI)
joined_df_new <- joined_df_new[, c(1,2,13,3:12,14,15)]

joined_df_long_new <- reshape(data = joined_df_new,
                              idvar= "new_year",
                              varying = 4:15, 
                              sep= "_",
                              timevar= "type",
                              times = c("MOI", "eMOI"),
                              new.row.names= 1:10000,
                              direction = "long")

joined_df_long_new <- joined_df_long_new %>%
  mutate(`Year (n)` = paste0(new_year, " (", N, ")"))

# Plot moi & emoi by new year group
AG_moi_plot <- joined_df_long_new %>% 
  filter(area == "Capital") %>%
  ggplot(aes(x = `Year (n)`, group = type)) +
  geom_pointrange(aes(y = mean, ymin = lower, ymax = upper, color = type),
                  position = position_dodge(width = 0), linetype = "dotted", size = 0.2) +
  geom_line(aes(y = mean, group = type, color = type)) +
  geom_point(aes(y = IR/10, group = 1), color = "gray") +
  geom_line(aes(y = IR/10, group = 1), color = "gray") +
  scale_y_continuous(name = "Estimate", sec.axis = sec_axis(~. / 10, name = "IR"), limits = c(0, 2)) +
  ggtitle("Capital") +
  theme_classic(base_size = 12) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 10))

nonAG_moi_plot <- joined_df_long_new %>% 
  filter(area == "Others") %>%
  ggplot(aes(x = `Year (n)`, group = type)) +
  geom_pointrange(aes(y = mean, ymin = lower, ymax = upper, color = type),
                  position = position_dodge(width = 0), linetype = "dotted", size = 0.2) +
  geom_line(aes(y = mean, group = type, color = type)) +
  geom_point(aes(y = IR/10, group = 1), color = "gray") +
  geom_line(aes(y = IR/10, group = 1), color = "gray") +
  scale_y_continuous(name = "Estimate", sec.axis = sec_axis(~. / 10, name = "IR"), limits = c(0, 2)) +
  ggtitle("Others") +
  theme_classic(base_size = 12) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 10))

plot_grid(AG_moi_plot + theme(legend.position = "none"),
          nonAG_moi_plot + theme(legend.position = "none"))


### IR*MOI plot
joined_df_long_new %>% filter(area == "Capital") %>%
  ggplot(aes(x = `Year (n)`, group = type)) +
  geom_point(aes(y = IRm, color = type)) +
  geom_line(aes(y = IRm, group = type, color = type)) +
  theme_minimal(base_size = 12) +
  ggtitle("Capital") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 10)) +
  ylab("IR% * MOI")

joined_df_long_new %>% filter(area == "Others") %>%
  ggplot(aes(x = `Year (n)`, group = type)) +
  geom_point(aes(y = IRm, color = type)) +
  geom_line(aes(y = IRm, group = type, color = type)) +
  theme_minimal(base_size = 12) +
  ggtitle("Others") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 10)) +
  ylab("IR% * MOI")

```



**Plot rw & polyclonal proportion by new year groups**
```{r rw & poly_prop by new year, echo=FALSE, warning = FALSE, message= FALSE}

### Merge data & Define polyclonal infection as eMOI mean > 1.1
moire_infection_new <- new_meta%>%
  group_by(new_year, area, infection) %>%
  summarize(count = n())
moire_infection_new %<>% pivot_wider(names_from = infection, values_from = count)
moire_infection_new %<>% mutate(N = mono + poly) %<>% 
  mutate(Polyclonal = round(poly/N, 3)*100, Monoclonal = round(mono/N, 3)*100)

moire_infection_new$IR = IR_merge$new_IR_perc

moire_infection_long_new <- moire_infection_new %>%
  pivot_longer(
    cols = c(Monoclonal, Polyclonal),  
    names_to = "Infection",    
    values_to = "Frequency")

moire_infection_long_new <- moire_infection_long_new %>%
  mutate(`Year (n)` = paste0(new_year, " (", N, ")"))

moire_infection_long_new %>% group_by(new_year, Infection) %>% summarize(n())


### Calculate annual average of rw mean by new year groups
rw_dist_new <- new_meta %>%
  filter(infection == "poly") %>%
  group_by(new_year, area) %>%
  summarize(N_rw = n(),
            mean_rw = mean(post_relatedness_mean),
            se_rw = se(post_relatedness_mean),
            upper_rw = mean_rw + se_rw,
            lower_rw = mean_rw - se_rw)
# Plot rw
moi_dist_select <- moi_dist_new %>% dplyr::select(new_year, area, N_MOI)
rw_dist_new <- inner_join(rw_dist_new, moi_dist_select)
rw_dist_new %<>% mutate(poly_prop = N_rw/N_MOI * 100)
rw_dist_new <- rw_dist_new %>%
  mutate(`Year (n)` = paste0(new_year, " (", N_rw, ")"))

AG_rw_plot <- rw_dist_new %>% filter(area == "Capital") %>%
ggplot(aes(x = `Year (n)`)) +
  geom_pointrange(aes(y = mean_rw, ymin = lower_rw, ymax = upper_rw)) +
  theme_minimal(base_size = 10) +
  scale_y_continuous(name = "Within-host relatedness", breaks = seq(0,1, by=.1)) +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ggtitle("Capital") +
  coord_cartesian(ylim = c(0, max(rw_dist_new$upper_rw, na.rm = TRUE)))


nonAG_rw_plot <- rw_dist_new %>% filter(area == "Others") %>%
  ggplot(aes(x = `Year (n)`)) +
  geom_pointrange(aes(y = mean_rw, ymin = lower_rw, ymax = upper_rw)) +
  theme_minimal(base_size = 10) +
  scale_y_continuous(name = "Within-host relatedness", breaks = seq(0,1, by=.1)) +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ggtitle("Others") +
  coord_cartesian(ylim = c(0, max(rw_dist_new$upper_rw, na.rm = TRUE)))


### Make combine plot of IRalence, polyclonal sample proportion, and rw
#AG
AG_poly_plot <- moire_infection_long_new %>%
  filter(area == "Capital") %>%
  ggplot(aes(x = `Year (n)`, y = Frequency, group = Infection)) +
  geom_col(aes(fill = Infection, alpha = 0.9)) +
  geom_line(aes(y = IR, color = "IR %")) +
  xlab("Year (n)") +
  ylab("Frequency %") +
  scale_color_manual(values = c("IR %" = "black")) +
  scale_y_continuous(name = "Frequency %", breaks = seq(0,100, by=10)) +
  theme_classic() +
  ggtitle("Capital") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 10)) 

# Non-AG
nonAG_poly_plot <- moire_infection_long_new %>%
  filter(area == "Others") %>%
  ggplot(aes(x = `Year (n)`, y = Frequency, group = Infection)) +
  geom_col(aes(fill = Infection, alpha = 0.9)) +
  geom_line(aes(y = IR, color = "IR %")) +
  xlab("Year (n)") +
  ylab("Frequency %") +
  scale_color_manual(values = c("IR %" = "black")) +
  scale_y_continuous(name = "Frequency %", breaks = seq(0,100, by=10)) +
  theme_classic() +
  ggtitle("Others") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 10))

# Combined plot
plot_grid(AG_poly_plot + theme(legend.position = "none"),
          AG_rw_plot + theme(legend.position = "none"))
plot_grid(nonAG_poly_plot + theme(legend.position = "none"),
          nonAG_rw_plot + theme(legend.position = "none"))
plot_grid(AG_poly_plot + theme(legend.position = "none"),
          nonAG_poly_plot + theme(legend.position = "none"))

# Report summary of poly prop in capital & others
a <- moire_infection_long_new %>% 
  filter(area == "Capital") %>% 
  filter(Infection == "Polyclonal") %>% 
  pull(Frequency)
summary(a)  

b <- moire_infection_long_new %>% 
  filter(area == "Others") %>% 
  filter(Infection == "Polyclonal") %>%
  pull(Frequency)
summary(b) 


### Plot rw of polyclonal infections from raw data
poly_data <- new_meta %>% filter(infection == "poly") #Total 106ï¼Œ11%

poly_data %>%
  ggplot(aes(x = new_year)) +
  geom_boxplot(aes(y = post_relatedness_mean)) +
  theme_minimal(base_size = 12) +
  ylab("Within-host relatedness") +
  xlab("Year (n)")
  ggtitle("rw by year")
  
# Perform Kruskal-Wallis test
kruskal.test(post_relatedness_mean ~ new_year, data = poly_data)

# Perform pairwise comparisons (post-hoc test) using Dunn's test
dunn.test(poly_data$post_relatedness_mean, g = poly_data$new_year, method = "bonferroni")

```


**moire by season groups**
```{r moire by season, echo=FALSE, warning = FALSE, message= FALSE}

# Assign season groups for metadata and IR
new_meta <- new_meta %>%
  mutate(season = case_when(
  between(Onset, as.Date("2010/3/1"), as.Date("2010/7/31")) ~ "2010_H",
  between(Onset, as.Date("2010/8/1"), as.Date("2010/11/30")) ~ "2010_L",
  between(Onset, as.Date("2010/12/1"), as.Date("2011/3/31")) ~ "2010_M",
  between(Onset, as.Date("2011/4/1"), as.Date("2011/7/31")) ~ "2011_H",
  between(Onset, as.Date("2011/9/1"), as.Date("2012/3/31")) ~ "2011_LM",
  between(Onset, as.Date("2012/4/1"), as.Date("2012/7/31")) ~ "2012_H",
  between(Onset, as.Date("2012/8/1"), as.Date("2012/11/30")) ~ "2012_L",
  between(Onset, as.Date("2012/12/1"), as.Date("2013/3/31")) ~ "2012_M",
  between(Onset, as.Date("2013/4/1"), as.Date("2013/7/31")) ~ "2013_H",
  between(Onset, as.Date("2013/8/1"), as.Date("2013/11/30")) ~ "2013_L",
  between(Onset, as.Date("2013/12/1"), as.Date("2014/3/31")) ~ "2013_M",
  between(Onset, as.Date("2014/4/1"), as.Date("2014/7/31")) ~ "2014_H",
  between(Onset, as.Date("2014/8/1"), as.Date("2014/11/30")) ~ "2014_L",
  between(Onset, as.Date("2014/12/1"), as.Date("2015/3/31")) ~ "2014_M",
  between(Onset, as.Date("2015/4/1"), as.Date("2015/7/31")) ~ "2015_H",
  between(Onset, as.Date("2015/8/1"), as.Date("2015/11/30")) ~ "2015_L",
  between(Onset, as.Date("2015/12/1"), as.Date("2016/3/31")) ~ "2015_M",
  between(Onset, as.Date("2016/4/1"), as.Date("2016/10/31")) ~ "2016_HL",
  TRUE ~ "Other" ))

IR <- IR %>%
  mutate(season = case_when(
    (Year == 2010 & Month >= 3 & Month <= 7)  ~ "2010_H",
    (Year == 2010 & Month >= 8 & Month <= 11) ~ "2010_L",
    (Year == 2010 & Month >= 12) | (Year == 2011 & Month <= 3)  ~ "2010_M",
    (Year == 2011 & Month >= 4 & Month <= 7) ~ "2011_H",
    (Year == 2011 & Month >= 9) | (Year == 2012 & Month <= 3) ~ "2011_LM",
    (Year == 2012 & Month >= 4 & Month <= 7) ~ "2012_H",
    (Year == 2012 & Month >= 8 & Month <= 11) ~ "2012_L",
    (Year == 2012 & Month >= 12) | (Year == 2013 & Month <= 3) ~ "2012_M",
    (Year == 2013 & Month >= 4 & Month <= 7) ~ "2013_H",
    (Year == 2013 & Month >= 8 & Month <= 11)  ~ "2013_L",
    (Year == 2013 & Month >= 12) | (Year == 2014 & Month <= 3) ~ "2013_M",
    (Year == 2014 & Month >= 4 & Month <= 7) ~ "2014_H",
    (Year == 2014 & Month >= 8 & Month <= 11)  ~ "2014_L",
    (Year == 2014 & Month >= 12) | (Year == 2015 & Month <= 3) ~ "2014_M",
    (Year == 2015 & Month >= 4 & Month <= 7)  ~ "2015_H",
    (Year == 2015 & Month >= 8 & Month <= 11) ~ "2015_L",
    (Year == 2015 & Month >= 12) | (Year == 2016 & Month <= 3) ~ "2015_M",
    (Year == 2016 & Month >= 4 & Month <= 10) ~ "2016_HL",
    TRUE ~ "Other" ))

# Calculate IR by season
season_pop <- read.csv("C:/Users/User1/SynologyDrive/UCSF work/STP data/ParagonV4/combine_list/season_pop.csv",
header = T)
IR_season <- inner_join(IR, season_pop)

# Sum up cases by season
IR_case_ss <- IR %>%
  group_by(season) %>%
  summarize(case = sum(case1))

IR_merge_ss <- inner_join(IR_case_ss, season_pop)

IR_merge_ss %<>%
  mutate(IR_ss = case/total_pop)

# Plot nationwide IR by season
IR_merge_ss %>%
  ggplot() +
  geom_point(aes(x = season, y = IR_ss *100)) +
  geom_line(aes(x = season, y = IR_ss * 100, group = 1)) +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8)) +
  ylab("Incidence %")

# Calculate average MOI
moi_dist_ss <- new_meta %>%
  group_by(season) %>%
  summarize(N_MOI = n(),
            mean_MOI = mean(post_coi_mean),
            se_MOI = se(post_coi_mean),
            upper_MOI = mean_MOI + se_MOI,
            lower_MOI = mean_MOI - se_MOI)

moi_dist_ss %>%
ggplot(aes(x = season)) +
  geom_pointrange(aes(y = mean_MOI, ymin = lower_MOI, ymax = upper_MOI),
                  position = position_dodge(width = 0.7)) +
  theme_minimal(base_size = 12) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8)) +
  ylab("MOI") +
  ggtitle("MOI by season")
    

# Calculate average eMOI
emoi_dist_ss <- new_meta %>%
  group_by(season) %>%
  summarize(N_eMOI = n(),
            mean_eMOI = mean(post_effective_coi_mean),
            se_eMOI = se(post_effective_coi_mean),
            upper_eMOI = mean_eMOI + se_eMOI,
            lower_eMOI = mean_eMOI - se_eMOI)

emoi_dist_ss %>%
  ggplot(aes(x = season)) +
  geom_pointrange(aes(y = mean_eMOI, ymin = lower_eMOI, ymax = upper_eMOI),
                  position = position_dodge(width = 0.7)) +
  theme_minimal(base_size = 12) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8)) +
  ylab("eMOI") +
  ggtitle("eMOI by season")

#### Combine MOI, eMOI, rw into joined_df
joined_df_ss <- inner_join(moi_dist_ss, emoi_dist_ss)
joined_df_ss$IR = IR_merge_ss$IR_ss
joined_df_ss %<>% mutate (IRm_MOI = IR*mean_MOI,
                          IRm_eMOI = IR*mean_eMOI)
joined_df_ss<- joined_df_ss[, c(1,12:14,2:11)]
joined_df_long_ss <- reshape(data = joined_df_ss,
                              idvar= "season",
                              varying = 3:14, 
                              sep= "_",
                              timevar= "type",
                              times = c("MOI", "eMOI"),
                              new.row.names= 1:10000,
                              direction = "long")
joined_df_long_ss <- joined_df_long_ss %>%
  mutate(`Season (N)` = paste0(season, " (", N, ")"))

# Plot MOI & eMOI by season
joined_df_long_ss %>% 
  ggplot(aes(x = `Season (N)`, group = type)) +
  geom_pointrange(aes(y = mean, ymin = lower, ymax = upper, color = type, alpha = 0.5),
                  position = position_dodge(width = 0), linetype = "dotted") +
  geom_line(aes(y = mean, group = type, color = type)) +
  geom_point(aes(y = IR * 20, group = 1), color = "gray") +
  geom_line(aes(y = IR * 20, group = 1), color = "gray") +
  scale_y_continuous(name = "Estimate", sec.axis = sec_axis(~./20, name = "IR")) +
  theme_classic(base_size = 12) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8)) +
  ylab("Estimate")

# Plot IR*MOI & IR*eMOI (IRm) by season
joined_df_long_ss %>% 
  ggplot(aes(x = `Season (N)`, group = type)) +
  geom_point(aes(y = IRm, color = type, alpha = 0.5)) +
  geom_line(aes(y = IRm, group = type, color = type)) +
  geom_point(aes(y = IR, group = 1), color = "gray") +
  geom_line(aes(y = IR, group = 1), color = "gray") +
  theme_classic(base_size = 12) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8)) +
  ylab("Estimate")

```


**moire by season and area groups**
```{r moire by season & area, echo=FALSE, warning = FALSE, message= FALSE}

# Calculate average MOI
moi_dist_ss_area <- new_meta %>%
  group_by(season, area) %>%
  summarize(N_MOI = n(),
            mean_MOI = mean(post_coi_mean),
            se_MOI = se(post_coi_mean),
            upper_MOI = mean_MOI + se_MOI,
            lower_MOI = mean_MOI - se_MOI)

# Calculate average eMOI
emoi_dist_ss_area <- new_meta %>%
  group_by(season, area) %>%
  summarize(N_eMOI = n(),
            mean_eMOI = mean(post_effective_coi_mean),
            se_eMOI = se(post_effective_coi_mean),
            upper_eMOI = mean_eMOI + se_eMOI,
            lower_eMOI = mean_eMOI - se_eMOI)

# Combined with MOI, eMOI, and IR
joined_df_ss_area <- inner_join(moi_dist_ss_area, emoi_dist_ss_area)

IR_merge_ss %<>% mutate(IR_ss_capital = case/Capital, IR_ss_others = case/Others)

cap <- joined_df_ss_area %>% filter(area == "Capital")
cap$IR_ss <- IR_merge_ss$IR_ss_capital

others <- joined_df_ss_area %>% filter(area == "Others")
others$IR_ss <- IR_merge_ss$IR_ss_others

joined_df_ss_area <- full_join(cap, others)

joined_df_ss_area %<>% mutate (IRm_MOI = IR_ss*mean_MOI,
                          IRm_eMOI = IR_ss*mean_eMOI)

joined_df_ss_area <- joined_df_ss_area[, c(1,2,13,3:12,14,15)]

# Make lond dataframe
joined_df_long_ss_area <- reshape(data = joined_df_ss_area,
                             idvar= "season",
                             varying = 4:15, 
                             sep= "_",
                             timevar= "type",
                             times = c("MOI", "eMOI"),
                             new.row.names= 1:10000,
                             direction = "long")
joined_df_long_ss_area <- joined_df_long_ss_area %>%
  mutate(`Season (N)` = paste0(season, " (", N, ")"))

# Plot MOI & eMOI by season & area
joined_df_long_ss_area %>% 
  filter(area == "Capital") %>%
  ggplot(aes(x = `Season (N)`, group = type)) +
  geom_pointrange(aes(y = mean, ymin = lower, ymax = upper, color = type, alpha = 0.5),
                  position = position_dodge(width = 0), linetype = "dotted") +
  geom_line(aes(y = mean, group = type, color = type)) +
  geom_point(aes(y = IR_ss * 10, group = 1), color = "gray") +
  geom_line(aes(y = IR_ss * 10, group = 1), color = "gray") +
  scale_y_continuous(name = "Estimate", sec.axis = sec_axis(~./10, name = "IR")) +
  theme_classic(base_size = 12) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8)) +
  ylab("Estimate") +
  ggtitle("Capital")

joined_df_long_ss_area %>% 
  filter(area == "Others") %>%
  ggplot(aes(x = `Season (N)`, group = type)) +
  geom_pointrange(aes(y = mean, ymin = lower, ymax = upper, color = type, alpha = 0.5),
                  position = position_dodge(width = 0), linetype = "dotted") +
  geom_line(aes(y = mean, group = type, color = type)) +
  geom_point(aes(y = IR_ss * 10, group = 1), color = "gray") +
  geom_line(aes(y = IR_ss * 10, group = 1), color = "gray") +
  scale_y_continuous(name = "Estimate", sec.axis = sec_axis(~./10, name = "IR")) +
  theme_classic(base_size = 12) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8)) +
  ylab("Estimate") +
  ggtitle("Others")


```


# Chapter 8 - Spatial-temporal analysis of dcifer results

**rb temporal heatmaps**
```{r rb new_year heatmap, echo=FALSE, warning = FALSE, message= FALSE}

### Turn rb matrix into paired df: (980^2 - 980) / 2 = 479710 unique pairs

# Create indices for upper triangle
dcifer_list <- read_rds("C:/Users/User1/SynologyDrive/UCSF work/STP data/ParagonV4/Cluster_plot/dcifer_list.rds")
dmat <- dcifer_list$relatedness
upper_triangle_indices <- upper.tri(dcifer_list$relatedness, diag = F)

# Create paired dataframe
pair_df <- data.frame(
  sample_1 = rownames(dmat)[row(dmat)[upper_triangle_indices]],
  sample_2 = colnames(dmat)[col(dmat)[upper_triangle_indices]],
  rb = dmat[upper_triangle_indices])

# Paste new_year info
new_meta_year <- new_meta %>% dplyr::select(sampleID, new_year)
pair_df <- merge(pair_df, new_meta_year, by.x = "sample_1", by.y = "sampleID")
pair_df %<>% rename(new_year_1 = new_year)
pair_df <- merge(pair_df, new_meta_year, by.x = "sample_2", by.y = "sampleID")
pair_df %<>% rename(new_year_2 = new_year)


# Combine new_year_1 and new_year_2 into a group column
pair_df <- pair_df %>%
  mutate(new_year_group = paste(new_year_1, new_year_2, sep = "_"))

# Combined group column: Year1_Year2 = Year2_Year1
pair_df$year_group <- apply(pair_df, 1, function(row) {
  sorted_row <- sort(unlist(c(row["new_year_1"], row["new_year_2"])), 
                     na.last = TRUE,
                     method = "radix",
                     decreasing = FALSE,
                     index.return = TRUE)
  sorted_year <- paste(sorted_row$x, collapse = "_")
  return(sorted_year)
})

# Calculate rb average
rb_year_group <- pair_df %>%
  group_by(year_group) %>%
  summarize(count = n(), mean_rb_perc = mean(rb) * 100)

# Plot distribution of rb for each group
pair_df %>%
  ggplot(aes(x = rb, group = new_year_group)) +  
  geom_histogram() +
  facet_wrap(~ year_group)

# Create a symmetric year_group column
rb_year_group <- rb_year_group %>%
  mutate(year_group_symmetric = paste(substr(year_group, 6, 9), substr(year_group, 1, 4), sep = "_"))

# Combine the data for symmetric pairs
rb_year_group_combined <- bind_rows(rb_year_group, mutate(rb_year_group, year_group = year_group_symmetric))

### Plot symmetric heatmap of mean rb
ggplot(rb_year_group_combined, aes(x = substr(year_group, 1, 4), y = substr(year_group, 6, 9), fill = mean_rb_perc)) +
  geom_tile() +
  scale_fill_gradient(name = "mean rb %", low = "white", high = "blue") +
  geom_text(aes(label = round(mean_rb_perc)), vjust = 1) +
  theme_minimal() +
  theme(
    axis.line = element_blank(),        # Remove axis lines
    panel.grid.major = element_blank(),  # Remove major grid lines
    panel.grid.minor = element_blank(),  # Remove minor grid lines
    panel.border = element_blank(),      # Remove panel border
  ) +
  xlab("") +
  ylab("")

### Plot the histogram distribution of rb across same-year pairs
pair_no <- pair_df %>% 
  filter(new_year_group %in% c("2010_2010", "2011_2011", "2012_2012", "2013_2013", "2014_2014", "2015_2015", "2016_2016")) %>%
  group_by(new_year_group) %>%
  summarize(n = n())


#2010
pair_2010 <- pair_df %>%
  filter(new_year_group == "2010_2010") %>%
  ggplot(aes(x = rb)) +
  geom_histogram(aes(y = ..count.. / sum(..count..) *100), bins = 30, fill = "gray", color = "black", alpha = 0.7) +
  scale_y_continuous(name = "Frequency (%)", breaks = seq(0,80,by=20), limits = c(0, 80)) +
  theme_classic()

pair_2010_zoom <- pair_df %>%
  filter(new_year_group == "2016_2016") %>%
  filter(rb >= 0.25 & rb < 0.9) %>%
  ggplot(aes(x = rb)) +
  geom_histogram(aes(y = ..count.. / pair_no$n[1] *100), bins = 30, fill = "gray", color = "black", alpha = 0.7) +
  scale_y_continuous(name = "Frequency (%)", breaks = seq(0,2,by=0.5), limits = c(0, 2)) +
  theme_classic() +
  ggtitle("2010")

#2011
pair_2011 <- pair_df %>%
  filter(new_year_group == "2011_2011") %>%
  ggplot(aes(x = rb)) +
  geom_histogram(aes(y = ..count.. / sum(..count..) *100), bins = 30, fill = "gray", color = "black", alpha = 0.7) +
  scale_y_continuous(name = "Frequency (%)", breaks = seq(0,80,by=20), limits = c(0, 80)) +
  theme_classic()

pair_2011_zoom <- pair_df %>%
  filter(new_year_group == "2011_2011") %>%
  filter(rb >= 0.25 & rb <= 0.9) %>%
  ggplot(aes(x = rb)) +
  geom_histogram(aes(y = ..count.. / pair_no$n[2] *100), bins = 30, fill = "gray", color = "black", alpha = 0.7) +
  scale_y_continuous(name = "Frequency (%)", breaks = seq(0,2,by=0.5), limits = c(0, 2)) +
  theme_classic() +
  ggtitle("2011")

#2012
pair_2012 <- pair_df %>%
  filter(new_year_group == "2012_2012") %>%
  ggplot(aes(x = rb)) +
  geom_histogram(aes(y = ..count.. / sum(..count..) *100), bins = 30, fill = "gray", color = "black", alpha = 0.7) +
  scale_y_continuous(name = "Frequency (%)", breaks = seq(0,80,by=20), limits = c(0, 80)) +
  theme_classic()

pair_2012_zoom <- pair_df %>%
  filter(new_year_group == "2012_2012") %>%
  filter(rb >= 0.25 & rb <= 0.9) %>%
  ggplot(aes(x = rb)) +
  geom_histogram(aes(y = ..count.. / pair_no$n[3] *100), bins = 30, fill = "gray", color = "black", alpha = 0.7) +
  scale_y_continuous(name = "Frequency (%)", breaks = seq(0,2,by=0.5), limits = c(0, 2)) +
  theme_classic() +
  ggtitle("2012")

#2013
pair_2013 <- pair_df %>%
  filter(new_year_group == "2013_2013") %>%
  ggplot(aes(x = rb)) +
  geom_histogram(aes(y = ..count.. / sum(..count..) *100), bins = 30, fill = "gray", color = "black", alpha = 0.7) +
  scale_y_continuous(name = "Frequency (%)", breaks = seq(0,80,by=20), limits = c(0, 80)) +
  theme_classic()

pair_2013_zoom <- pair_df %>%
  filter(new_year_group == "2013_2013") %>%
  filter(rb >= 0.25 & rb <= 0.9) %>%
  ggplot(aes(x = rb)) +
  geom_histogram(aes(y = ..count.. / pair_no$n[4] *100), bins = 30, fill = "gray", color = "black", alpha = 0.7) +
  scale_y_continuous(name = "Frequency (%)", breaks = seq(0,2,by=0.5), limits = c(0, 2)) +
  theme_classic() +
  ggtitle("2013")

#2014
pair_2014 <- pair_df %>%
  filter(new_year_group == "2014_2014") %>%
  ggplot(aes(x = rb)) +
  geom_histogram(aes(y = ..count.. / sum(..count..) *100), bins = 30, fill = "gray", color = "black", alpha = 0.7) +
  scale_y_continuous(name = "Frequency (%)", breaks = seq(0,80,by=20), limits = c(0, 80)) +
  theme_classic()

pair_2014_zoom <- pair_df %>%
  filter(new_year_group == "2014_2014") %>%
  filter(rb >= 0.25 & rb <= 0.9) %>%
  ggplot(aes(x = rb)) +
  geom_histogram(aes(y = ..count.. / pair_no$n[5] *100), bins = 30, fill = "gray", color = "black", alpha = 0.7) +
  scale_y_continuous(name = "Frequency (%)", breaks = seq(0,2,by=0.5), limits = c(0, 2)) +
  theme_classic() +
  ggtitle("2014")

#2015
pair_2015 <- pair_df %>%
  filter(new_year_group == "2015_2015") %>%
  ggplot(aes(x = rb)) +
  geom_histogram(aes(y = ..count.. / sum(..count..) *100), bins = 30, fill = "gray", color = "black", alpha = 0.7) +
  scale_y_continuous(name = "Frequency (%)", breaks = seq(0,80,by=20), limits = c(0, 80)) +
  theme_classic()

pair_2015_zoom <- pair_df %>%
  filter(new_year_group == "2015_2015") %>%
  filter(rb >= 0.25 & rb <= 0.9) %>%
  ggplot(aes(x = rb)) +
  geom_histogram(aes(y = ..count.. / pair_no$n[6] *100), bins = 30, fill = "gray", color = "black", alpha = 0.7) +
  scale_y_continuous(name = "Frequency (%)", breaks = seq(0,2,by=0.5), limits = c(0, 2)) +
  theme_classic() +
  ggtitle("2015")

#2016
pair_2016 <- pair_df %>%
  filter(new_year_group == "2016_2016") %>%
  ggplot(aes(x = rb)) +
  geom_histogram(aes(y = ..count.. / sum(..count..) *100), bins = 30, fill = "gray", color = "black", alpha = 0.7) +
  scale_y_continuous(name = "Frequency (%)", breaks = seq(0,80,by=20), limits = c(0, 80)) +
  theme_classic()

pair_2016_zoom <- pair_df %>%
  filter(new_year_group == "2016_2016") %>%
  filter(rb >= 0.25 & rb <= 0.9) %>%
  ggplot(aes(x = rb)) +
  geom_histogram(aes(y = ..count.. / pair_no$n[7] *100), bins = 30, fill = "gray", color = "black", alpha = 0.7) +
  scale_y_continuous(name = "Frequency (%)", breaks = seq(0,2,by=0.5), limits = c(0, 2)) +
  theme_classic() +
  ggtitle("2016")

plot_grid(pair_2010, pair_2011, pair_2012, pair_2013, pair_2014, pair_2015, pair_2016, 
                       ncol = 4, align = "hv")
plot_grid(pair_2010_zoom, pair_2011_zoom, pair_2012_zoom, pair_2013_zoom, pair_2014_zoom, 
          pair_2015_zoom, pair_2016_zoom, ncol = 4, align = "hv")

### Calculate rb proportion - 0.3/0.6/0.9
pair_df %<>%
  mutate(rb_0 = ifelse(rb == 0, 1, 0),
         rb_0.1 = ifelse(rb >= 0.1, 1, 0),
         rb_0.3 = ifelse(rb >= 0.3, 1, 0),
         rb_0.6 = ifelse(rb >= 0.6, 1, 0),
         rb_0.9 = ifelse(rb >= 0.9, 1, 0))

# rb >= 0.9
rb_0.9 <- pair_df %>%
  group_by(year_group, rb_0.9) %>%
  summarize(n = n())
rb_0.9 %<>% group_by(year_group) %>% mutate(total = sum(n))
rb_0.9 %<>% mutate(rbprop_0.9 = n/total *100)
rb_0.9_select <- rb_0.9 %>% filter(rb_0.9 == 1) %>% dplyr::select(year_group, rbprop_0.9)

# rb >= 0.6
rb_0.6 <- pair_df %>%
  group_by(year_group, rb_0.6) %>%
  summarize(n = n())
rb_0.6 %<>% group_by(year_group) %>% mutate(total = sum(n))
rb_0.6 %<>% mutate(rbprop_0.6 = n/total *100)
rb_0.6_select <- rb_0.6 %>% filter(rb_0.6 == 1) %>% dplyr::select(year_group, rbprop_0.6)

# rb >= 0.3
rb_0.3 <- pair_df %>%
  group_by(year_group, rb_0.3) %>%
  summarize(n = n())
rb_0.3 %<>% group_by(year_group) %>% mutate(total = sum(n))
rb_0.3 %<>% mutate(rbprop_0.3 = n/total *100)
rb_0.3_select <- rb_0.3 %>% filter(rb_0.3 == 1) %>% dplyr::select(year_group, rbprop_0.3)

# rb >= 0.1
rb_0.1 <- pair_df %>%
  group_by(year_group, rb_0.1) %>%
  summarize(n = n())
rb_0.1 %<>% group_by(year_group) %>% mutate(total = sum(n))
rb_0.1 %<>% mutate(rbprop_0.1 = n/total *100)
rb_0.1_select <- rb_0.1 %>% filter(rb_0.1 == 1) %>% dplyr::select(year_group, rbprop_0.1)

# Completely no rb (rb = 0)
rb_0 <- pair_df %>%
  group_by(year_group, rb_0) %>%
  summarize(n = n())
rb_0 %<>% group_by(year_group) %>% mutate(total = sum(n))
rb_0 %<>% mutate(rbprop_0 = n/total *100)
rb_0_select <- rb_0 %>% filter(rb_0 == 1) %>% dplyr::select(year_group, rbprop_0)

# Make heatmap df
df_list <- list(rb_year_group, rb_0_select, rb_0.1_select, rb_0.3_select, rb_0.6_select, rb_0.9_select)
rb_year_group <- df_list %>% reduce(full_join, by='year_group')
rb_year_group[is.na(rb_year_group)] <- 0

# Combine the data for symmetric pairs
rb_year_group_combined <- bind_rows(rb_year_group, mutate(rb_year_group, year_group = year_group_symmetric))

rb_prop_long <- reshape(data = rb_year_group_combined,
                        idvar= "year_group",
                        varying = 5:9, 
                        sep= "_",
                        timevar= "rb_level",
                        times = c(0, 0.1, 0.3, 0.6, 0.9),
                        new.row.names= 1:10000,
                        direction = "long")

# Plot combined heatmap for different rb levels
rb_prop_long %>%
  filter(rb_level %in% c(0.3, 0.6, 0.9)) %>%
  ggplot(aes(x = substr(year_group, 1, 4), y = substr(year_group, 6, 9), fill = rbprop, label = sprintf("%.1f%%", rbprop))) +
  geom_tile() +
  geom_text(aes(label = round(rbprop)), vjust = 1) + 
  scale_fill_gradient(name = "% of pairs", low = "white", high = "red", limits = c(0, 45)) +
  facet_wrap(~ rb_level, scales = "free", ncol = 3, labeller = labeller(rb_level = function(x) paste("rb >= ", x))) +
  xlab("") +
  ylab("") +
  theme_minimal(base_size = 12)

# Plot rb = 0 heatmap
rb_prop_long %>%
  filter(rb_level == 0) %>%
  ggplot(aes(x = substr(year_group, 1, 4), y = substr(year_group, 6, 9), fill = rbprop)) +
  geom_tile() +
  geom_text(aes(label = round(rbprop)), vjust = 1) + 
  scale_fill_gradient(name = "% of pairs", low = "white", high = "red") +
  xlab("") +
  ylab("") +
  theme_minimal(base_size = 12)

# How many pairs with rb >= 0.9 or 0.6 or 0.3 (Total pairs = 479710)
rb_0.9_pair_no <- pair_df %>% filter(rb >= 0.9) %>% nrow() #21735
print(sprintf("Prop. of pairs with rb >= 0.9 = %s%%", round(rb_0.9_pair_no/nrow(pair_df) * 100))) #4.5%

rb_0.6_pair_no <- pair_df %>% filter(rb >= 0.6) %>% nrow() #26349
print(sprintf("Prop. of pairs with rb >= 0.6 = %s%%", round(rb_0.6_pair_no/nrow(pair_df) * 100))) #5.5%

rb_0.25_pair_no <- pair_df %>% filter(rb >= 0.25) %>% nrow() #48180
print(sprintf("Prop. of pairs with rb >= 0.25 = %s%%", round(rb_0.25_pair_no/nrow(pair_df) * 100))) #10%

```

**rb temporal network plots**
```{r rb new_year network, echo=FALSE, warning = FALSE, message= FALSE}

# Input grouping files
setGroupsFromFile <- function(dcifer_list, filename)
{
  thisData <- read.csv(filename)
  group_ids <- as.vector(thisData[,1])
  group <- as.vector(thisData[,2])
  dcifer_list$group <- group
  if(!all(group_ids==dcifer_list$id)){
    print("Warning: IDs in group file don't match those on the model.")
    print(group_ids)
  }
  return(dcifer_list)
}

# Set group labels
setGroupLabels <- function(dcifer_list, filename){
  thisData <- read.csv(filename)
  labels <- as.vector(thisData[,2])
  dcifer_list$group_label <- labels
  return(dcifer_list)
}

# Set group colors
setGroupColours <- function(dcifer_list, filename){
  thisData <- read.csv(filename)
  colours <- as.vector(thisData[,3])
  dcifer_list$group_color <- colours
  return(dcifer_list)
}

GroupColour <- function(dcifer_list, group_label){
  index <- match(group_label, dcifer_list$group_label)
  if (is.na(index)) return ("white")
  return(dcifer_list$group_color[[index]])
}


# Cluster plot with grouping as vertex color
plotClusterGroup <- function(dcifer_list, level=0.5, alpha=0.05, vSize=2, thick=2, vFontSize=.5, labelOffset=1, legend_x=.5, legend_y=.5, group_name='Group', show_legend=TRUE, vertex_border_color='black', vertex_border_width=1, vertex_label=FALSE)
{
  edges <- NULL
  wgts <- NULL
  vcolours <- NULL
  isolates <- dcifer_list$id
  for (i in seq(length(dcifer_list$id)-1)){
    for (j in seq(i+1, length(dcifer_list$id))){
      if (dcifer_list$relatedness[i,j]>=level){
        if(dcifer_list$pvalue[i,j] < alpha){
          edges <- c(edges, dcifer_list$id[[i]], dcifer_list$id[[j]])
          wgts <- c(wgts, thick*dcifer_list$relatedness[i,j])
          isolates <- isolates[isolates != dcifer_list$id[[i]]]
          isolates <- isolates[isolates != dcifer_list$id[[j]]]
        }
      }
    }
  }
  
  gtitle <- paste0('Cluster plot for relatedness >= ',level, ' , by ', group_name)
  cgraph <- igraph::graph(edges=edges, isolates=isolates, directed=F)
  
  # Assign vertex colors
  for (c in 1:length(V(cgraph))){
    #since the names in the first column are only a part of all the nodes check if it belongs to that sublist
    if(V(cgraph)$name[c] %in% dcifer_list$id) {
      #then find the first occurrence of that name in the list and get its related color
      #assign it to that node
      V(cgraph)$color[c] <- as.character(dcifer_list$group_color[which(dcifer_list$id==V(cgraph)$name[c])[1]])
    }
    #otherwise the node will be white 
    else {
      V(cgraph)$color[c] <- "white"
    }
  }
  
  # Create a data frame for the legend with labels and corresponding colors
  legend_data <- data.frame(label = c(2005, 2010:2016),
                            color = c("black","gray","purple","blue","green","yellow","pink","red"))
  
  igraph::E(cgraph)$weight <- wgts
  
  # Adjust the vertex border size and color
  V(cgraph)$size <- vSize
  V(cgraph)$border.color <- vertex_border_color
  V(cgraph)$border.width <- vertex_border_width
  
  plot(cgraph, edge.width=igraph::E(cgraph)$weight, vertex.size=V(cgraph)$size, 
       vertex.color=igraph::V(cgraph)$color, vertex.shape=igraph::V(cgraph)$shape, 
       vertex.label.cex=vFontSize, vertex.label.dist=labelOffset, 
       vertex.label = ifelse(vertex_label, V(cgraph)$name, NA),
       vertex.frame.color = V(cgraph)$border.color,
       vertex.frame.width = V(cgraph)$border.width,
       main=gtitle, frame=TRUE)
  
  if (show_legend) {
    coord <- par("usr")
    graphics::legend("topright",  # Adjusted to right for right side
                     legend=legend_data$label,
                     fill=legend_data$color,
                     title=group_name,
                     xjust = legend_x, yjust = legend_y)
  }
  
  return(cgraph)
} 


# Example usage with vertex labels turned off
filename <- 'C:/Users/User1/SynologyDrive/UCSF work/STP data/ParagonV4/Cluster_plot/New_time_info.csv'
dcifer_list <- setGroupsFromFile(dcifer_list, filename)
dcifer_list <- setGroupColours(dcifer_list, filename)
dcifer_list <- setGroupLabels(dcifer_list, filename)

cluster_plot <- plotClusterGroup(dcifer_list, level=0.9, alpha=0.05, 
                                 vSize=1.4, thick=1, show_legend=F, group_name='Year', vertex_border_color='grey5', vertex_border_width=0.8, vertex_label=F)

cluster_plot

```


**Cluster size temporal changes**
```{r temporal cluster size, echo=FALSE, warning = FALSE, message= FALSE}

### Extract length > 1 sublist
g1 <- igraph::max_cliques(cluster_plot)
cluster_list <- lapply(g1, names)
# This cluster_list would link to the level you set for cluster_plot (in this case would report samples with R>=0.9)

result_list <- list()
for (sublist in cluster_list) {
  if (length(sublist) > 1) {
    result_list <- append(result_list, list(sublist))
  }
}

### Merge sublists with overlapping elements
merge_overlap <- function(lst) {
  # Create an empty list to store merged sublists
  merged_list <- list()
  
  for (sublist in lst) {
    # Check if the sublist has any overlapping elements with existing merged sublists
    overlapping_index <- sapply(merged_list, function(merged_sublist) any(sublist %in% merged_sublist))
    
    if (any(overlapping_index)) {
      # Merge the sublist with overlapping sublists
      merged_sublist <- unique(unlist(c(sublist, merged_list[overlapping_index])))
      
      # Remove the overlapping sublists
      merged_list <- merged_list[!overlapping_index]
      
      # Add the merged sublist to the merged_list
      merged_list <- append(merged_list, list(merged_sublist))
    } else {
      # Add the original sublist to the merged_list
      merged_list <- append(merged_list, list(sublist))
    }
  }
  
  return(merged_list)
}

# Merge sublists with overlapping elements
merged_result_list <- merge_overlap(result_list)

### Turn the list into dataframe
# Initialize empty vectors to store values and sublist numbers
all_values <- c()
sublist_number <- c()

# Iterate through the merged_result_list
for (i in seq_along(merged_result_list)) {
  values <- merged_result_list[[i]]
  
  # Extend the all_values vector with the values from the current sublist
  all_values <- c(all_values, values)
  
  # Extend the sublist_number vector with the corresponding sublist number for each value
  sublist_number <- c(sublist_number, rep(i, length(values)))
}

# Create a dataframe from the vectors
cluster_df <- data.frame(Values = all_values, SublistNumber = sublist_number)
cluster_df %<>% rename(sampleID = Values, cluster = SublistNumber)
cluster_df <- merge(cluster_df, new_meta, by = "sampleID")
cluster_df %<>% arrange(cluster, new_year)


### Identify if within-cluster is crossed-years or not
# Initialize a vector to store the labels
cross_new_year <- character(nrow(cluster_df))

# Iterate through the cluster_df to label cross-years or not-crossed 
for (cluster in unique(cluster_df$cluster)) {
  cluster_indices <- which(cluster_df$cluster == cluster)
  
  if (length(unique(cluster_df$new_year[cluster_indices])) == 1) {
    cross_new_year[cluster_indices] <- 0
  } else {
    cross_new_year[cluster_indices] <- 1
  }
}

cluster_df$cross_new_year <- cross_new_year

write.csv(cluster_df, "cluster_df.csv")

### Details of cross-year clusters and non-crossed clusters
cluster_df %>% group_by(cross_new_year) %>% summarize(cluster_no = n_distinct(cluster))
no_cross <- cluster_df %>% filter(cross_new_year == 0) %>% group_by(cluster) %>% summarize(n = n()) 
cross <- cluster_df %>% filter(cross_new_year == 1) %>% group_by(cluster) %>% summarize(n = n())

all_cluster <- rbind(no_cross, cross)
all_cluster <- all_cluster %>%
  mutate(crossed_years = ifelse(cluster %in% no_cross$cluster, "N", "Y"))

ggplot(all_cluster, aes(x = n, fill = crossed_years)) +
  geom_density(alpha = 0.7) +
  labs(fill = "Crossed Years") +
  xlab("Cases") +
  theme_minimal() +
  scale_x_continuous(breaks = seq(0,200, by = 10))


### Plot all clusters by new year groups
cluster_df <- left_join(cluster_df, all_cluster, by = "cluster")
cluster_df$cluster <- sprintf("%02d", cluster_df$cluster)

cluster_time_trend <- cluster_df %>% 
  group_by(new_year, cluster) %>%
  summarize(Cases = n_distinct(sampleID)) %>%
  arrange(cluster, new_year)

cluster_time_trend <- cluster_time_trend %>% group_by(cluster) %>% 
  mutate(Start = min(new_year)) %>% ungroup

cluster_time_trend$cluster <- as.factor(cluster_time_trend$cluster)
cluster_time_trend$Start <- as.integer(cluster_time_trend$Start)

cluster_time_trend %>%
  group_by(cluster) %>%
  ggplot(aes(x = new_year, y = reorder(cluster, -Start), group = cluster)) +
  geom_line(aes(alpha = 0.05, color = factor(cluster))) +  # Added color aesthetic
  geom_point(aes(size = Cases, alpha = 0.05, color = factor(cluster))) +  # Added color aesthetic
  scale_size_continuous(range = c(1, 5), name = "Cases") +
  scale_color_manual(values = c("61" = "blue", "62" = "red", "other" = "black")) +  # Assign colors
  labs(x = "Year", y = "Cluster") +
  theme_classic(base_size = 9) +
  expand_limits(y = 65) +
  theme(plot.margin = margin(t = 25, r = 10, b = 0, l = 10))

```


**rb spatial heatmaps**
```{r rb spatial heatmap, echo=FALSE, warning = FALSE, message= FALSE}

# Select grouping variables from metadata
new_meta_spatial <- new_meta %>% dplyr::select(sampleID, District, Location, dis_loc, area, new_year)

### Overall distribution of dis_loc
District_Location <- new_meta_spatial %>% 
  group_by(dis_loc) %>%
  summarize(Count=n()) %>%
  mutate(Prop = Count/sum(Count)) %>% 
  mutate(Labels = paste0(round((Count/ sum(Count)) * 100, 1), "%", " (", Count, ") "))

level = c("AG-Q1", "AG-Q2", "MZ-Q1", "MZ-Q2", "LO-Q1", "LO-Q2", "CT-Q1", "CT-Q2", "LE_CU_PR")
colors = c("firebrick3","firebrick1","darkorange2","darkorange","gold3","gold2",
           "darkolivegreen3","darkolivegreen2","lightskyblue")

District_Location %>%
  ggplot(aes(x = "", y = Count, fill = factor(dis_loc, levels = level))) +
  geom_bar(stat="identity", width=1, alpha=0.7) +
  scale_fill_manual(name = "District", values = colors) +
  coord_polar("y", start=0) +
  ggtitle ("Residency of samples") +
  geom_text(aes(x = 1.6, y = Count, label = Labels), position = position_stack(vjust = .5), size=2.3)+
  theme_void() 

### Merge spatial info with pair_df
spatial_group <- new_meta_spatial %>% dplyr::select(sampleID, District)
pair_df <- merge(pair_df, spatial_group, by.x = "sample_1", by.y = "sampleID", all.x = T)
pair_df %<>% rename(District_1 = District)

pair_df <- merge(pair_df, spatial_group, by.x = "sample_2", by.y = "sampleID", all.x = T)
pair_df %<>% rename(District_2 = District)

# Combined group column
district_order <- c("AG", "LO", "MZ", "CT", "LE", "PR")

pair_df <- pair_df %>%
  mutate(District_pair = paste(District_1, District_2, sep = "_"))

pair_df$district_group <- apply(pair_df, 1, function(row) {
  sorted_row <- sort(c(row["District_1"], row["District_2"]), 
                     na.last = TRUE,
                     method = "radix",
                     decreasing = FALSE,
                     index.return = TRUE)
  sorted_districts <- sorted_row$x[order(match(sorted_row$x, district_order))]
  paste(sorted_districts, collapse = "_")
})


# Calculate rb average
rb_district <- pair_df %>%
  group_by(district_group) %>%
  summarize(count = n(), mean_rb_perc = mean(rb) * 100)

# Create a symmetric district_group column
rb_district_group <- rb_district %>%
  mutate(district_group_symmetric = paste(substr(district_group, 4, 5), substr(district_group, 1, 2), sep = "_"))

# Combine the data for symmetric pairs
rb_district_group_combined <- bind_rows(rb_district_group, mutate(rb_district_group, district_group = district_group_symmetric))
rb_district_group_combined %<>% separate(district_group, into = c("x_axis", "y_axis"), sep = "_")

# Plot spatial mean rb heatmap
ggplot(rb_district_group_combined, 
       aes(x = factor(x_axis, levels = district_order), 
           y = factor(y_axis, levels = district_order), fill = mean_rb_perc)) +
  geom_tile(color = "darkgray") +
  #geom_text(aes(label = round(mean_rb_perc)), vjust = 1) +
  scale_fill_gradient(name = "mean rb %", low = "white", high = "darkgreen") +
  theme_minimal(base_size = 20) +
  theme(
    axis.line = element_blank(),        # Remove axis lines
    panel.grid.major = element_blank(),  # Remove major grid lines
    panel.grid.minor = element_blank(),  # Remove minor grid lines
    panel.border = element_blank(),      # Remove panel border
  ) +
  xlab("") +
  ylab("")

# Plot pair counts heatmap
ggplot(rb_district_group_combined, 
       aes(x = factor(x_axis, levels = district_order), 
           y = factor(y_axis, levels = district_order), fill = count)) +
  geom_tile(color = "darkgray") +
  #geom_text(aes(label = count), vjust = 1) +
  scale_fill_gradient(name = "No. of pairs", low = "white", high = "dodgerblue") +
  theme_minimal() +
  theme(
    axis.line = element_blank(),        # Remove axis lines
    panel.grid.major = element_blank(),  # Remove major grid lines
    panel.grid.minor = element_blank(),  # Remove minor grid lines
    panel.border = element_blank(),      # Remove panel border
  ) +
  xlab("") +
  ylab("")

### Calculate mean rb by districts & years - only for sample pairs in the same year
pair_df %<>% 
  mutate(cross = ifelse(new_year_1 == new_year_2, 0, 1))

cdist <- pair_df %>% mutate(cdist_1 = ifelse(
  District_1 %in% c("LE", "PR"), "LEPR", District_1),
  cdist_2 = ifelse(District_2 %in% c("LE", "PR"), "LEPR", District_2)) %>%
  mutate(cdist_pair = paste(cdist_1, cdist_2, sep = "_"))

cdist_order <- c("AG", "LO", "MZ", "CT", "LEPR")

cdist$cdist_group <- apply(cdist, 1, function(row) {
  sorted_row <- sort(c(row["cdist_1"], row["cdist_2"]), 
                     na.last = TRUE,
                     method = "radix",
                     decreasing = FALSE,
                     index.return = TRUE)
  sorted_districts <- sorted_row$x[order(match(sorted_row$x, cdist_order))]
  paste(sorted_districts, collapse = "_")
})  

# Pairs that did not cross years
result <- cdist %>% filter(cross == 0) %>%
  group_by(new_year_1, cdist_group) %>%
  summarize(count = n(), mean_rb_perc = mean(rb) * 100) %>%
  separate(cdist_group, into = c("x_axis", "y_axis"), sep = "_") 


# Plot the heatmap with facets
ggplot(result, 
       aes(x = factor(x_axis, levels = cdist_order), 
           y = factor(y_axis, levels = cdist_order), fill = mean_rb_perc)) +
  geom_tile(color = "darkgray") +
  geom_text(aes(label = round(mean_rb_perc)), vjust = 1) +
  scale_fill_gradient(name = "mean rb %", low = "white", high = "red") +
  theme_minimal() +
  theme(
    axis.line = element_blank(),        # Remove axis lines
    panel.grid.major = element_blank(),  # Remove major grid lines
    panel.grid.minor = element_blank(),  # Remove minor grid lines
    panel.border = element_blank(),      # Remove panel border
  ) +
  xlab("") +
  ylab("") +
  facet_wrap(~ new_year_1)

# Plot pair counts heatmap
ggplot(result, 
       aes(x = factor(x_axis, levels = cdist_order), 
           y = factor(y_axis, levels = cdist_order), fill = count)) +
  geom_tile(color = "darkgray") +
  geom_text(aes(label = count), vjust = 1) +
  scale_fill_gradient(name = "No. of pairs", low = "white", high = "dodgerblue") +
  theme_minimal() +
  theme(
    axis.line = element_blank(),        # Remove axis lines
    panel.grid.major = element_blank(),  # Remove major grid lines
    panel.grid.minor = element_blank(),  # Remove minor grid lines
    panel.border = element_blank(),      # Remove panel border
  ) +
  xlab("") +
  ylab("") +
  facet_wrap(~ new_year_1)

```


**rb spatial network plot**
```{r rb spatial network, echo=FALSE, warning = FALSE, message= FALSE}
# Input grouping files
setGroupsFromFile <- function(dcifer_list, filename)
{
  thisData <- read.csv(filename)
  group_ids <- as.vector(thisData[,1])
  group <- as.vector(thisData[,2])
  dcifer_list$group <- group
  if(!all(group_ids==dcifer_list$id)){
    print("Warning: IDs in group file don't match those on the model.")
    print(group_ids)
  }
  return(dcifer_list)
}

# Set group labels
setGroupLabels <- function(dcifer_list, filename){
  thisData <- read.csv(filename)
  labels <- as.vector(thisData[,2])
  dcifer_list$group_label <- labels
  return(dcifer_list)
}

# Set group colors
setGroupColours <- function(dcifer_list, filename){
  thisData <- read.csv(filename)
  colours <- as.vector(thisData[,3])
  dcifer_list$group_color <- colours
  return(dcifer_list)
}

GroupColour <- function(dcifer_list, group_label){
  index <- match(group_label, dcifer_list$group_label)
  if (is.na(index)) return ("white")
  return(dcifer_list$group_color[[index]])
}


# Cluster plot with grouping as vertex color
plotClusterGroup <- function(dcifer_list, level=0.5, alpha=0.05, vSize=2, thick=2, vFontSize=.5, labelOffset=1, legend_x=.5, legend_y=.5, group_name='Group', show_legend=TRUE, vertex_border_color='black', vertex_border_width=1, vertex_label=FALSE)
{
  edges <- NULL
  wgts <- NULL
  vcolours <- NULL
  isolates <- dcifer_list$id
  for (i in seq(length(dcifer_list$id)-1)){
    for (j in seq(i+1, length(dcifer_list$id))){
      if (dcifer_list$relatedness[i,j]>=level){
        if(dcifer_list$pvalue[i,j] < alpha){
          edges <- c(edges, dcifer_list$id[[i]], dcifer_list$id[[j]])
          wgts <- c(wgts, thick*dcifer_list$relatedness[i,j])
          isolates <- isolates[isolates != dcifer_list$id[[i]]]
          isolates <- isolates[isolates != dcifer_list$id[[j]]]
        }
      }
    }
  }
  
  gtitle <- paste0('Cluster plot for relatedness >= ',level, ' , by ', group_name)
  cgraph <- igraph::graph(edges=edges, isolates=isolates, directed=F)
  
  # Assign vertex colors
  for (c in 1:length(V(cgraph))){
    #since the names in the first column are only a part of all the nodes check if it belongs to that sublist
    if(V(cgraph)$name[c] %in% dcifer_list$id) {
      #then find the first occurrence of that name in the list and get its related color
      #assign it to that node
      V(cgraph)$color[c] <- as.character(dcifer_list$group_color[which(dcifer_list$id==V(cgraph)$name[c])[1]])
    }
    #otherwise the node will be white 
    else {
      V(cgraph)$color[c] <- "white"
    }
  }
  
  
  # Create a data frame for the legend with labels and corresponding colors
  legend_data <- data.frame(label = c("AG", "MZ", "LO", "CT", "LE", "PR"),
                            color = c("red", "green", "blue", "yellow", "purple", "gray"))
  
  igraph::E(cgraph)$weight <- wgts
 
   # Adjust the vertex border size and color
  V(cgraph)$size <- vSize
  V(cgraph)$border.color <- vertex_border_color
  V(cgraph)$border.width <- vertex_border_width
  
  plot(cgraph, edge.width=igraph::E(cgraph)$weight, vertex.size=V(cgraph)$size, 
       vertex.color=igraph::V(cgraph)$color, vertex.shape=igraph::V(cgraph)$shape, 
       vertex.label.cex=vFontSize, vertex.label.dist=labelOffset, 
       vertex.label = ifelse(vertex_label, V(cgraph)$name, NA),
       vertex.frame.color = V(cgraph)$border.color,
       vertex.frame.width = V(cgraph)$border.width,
       main=gtitle, frame=TRUE)
  
  if (show_legend) {
    coord <- par("usr")
    graphics::legend("topright",  # Adjusted to right for right side
                     legend=legend_data$label,
                     fill=legend_data$color,
                     title=group_name,
                     xjust = legend_x, yjust = legend_y)
  }
  
  return(cgraph)
} 


# Run with group-assigned file
filename <- 'C:/Users/User1/SynologyDrive/UCSF work/STP data/ParagonV4/Cluster_plot/New_district_info.csv'
dcifer_list <- setGroupsFromFile(dcifer_list, filename)
dcifer_list <- setGroupColours(dcifer_list, filename)
dcifer_list <- setGroupLabels(dcifer_list, filename)

spatial_plot <- plotClusterGroup(dcifer_list, level=0.9, alpha=0.05, 
                                 vSize=1.4, thick = 1, show_legend = T, legend_x = 1, legend_y = .5, 
                                 group_name='District', vertex_border_color='grey5', 
                                 vertex_border_width=0.8, vertex_label=F)

spatial_plot

```
***Between-cluster relationships***
```{r rb cluster heatmap, echo=FALSE, warning = FALSE, message= FALSE}

# Create indices for upper triangle
new_meta <- read.csv("C:/Users/User1/SynologyDrive/UCSF work/STP data/ParagonV4/combine_list/new_meta.csv")
dcifer_list <- read_rds("C:/Users/User1/SynologyDrive/UCSF work/STP data/ParagonV4/Cluster_plot/dcifer_list.rds")
dmat <- dcifer_list$relatedness
upper_triangle_indices <- upper.tri(dcifer_list$relatedness, diag = F)

# Create paired dataframe
pair_df <- data.frame(
  sample_1 = rownames(dmat)[row(dmat)[upper_triangle_indices]],
  sample_2 = colnames(dmat)[col(dmat)[upper_triangle_indices]],
  rb = dmat[upper_triangle_indices])

# Paste cluster info
new_meta_cluster <- new_meta %>% dplyr::select(sampleID, cluster)
pair_df <- merge(pair_df, new_meta_cluster, by.x = "sample_1", by.y = "sampleID")
pair_df %<>% rename(cluster_1 = cluster)
pair_df <- merge(pair_df, new_meta_cluster, by.x = "sample_2", by.y = "sampleID")
pair_df %<>% rename(cluster_2 = cluster)

pair_df <- pair_df %>%
  filter(!is.na(cluster_1)) %>%
  filter(!is.na(cluster_2))

# Combine cluster_1 and cluster_2 into a group column
pair_df$cluster_1 <- sprintf("%02d", pair_df$cluster_1)
pair_df$cluster_2 <- sprintf("%02d", pair_df$cluster_2)

pair_df <- pair_df %>%
  mutate(cluster_group = paste(cluster_1, cluster_2, sep = "_"))

# Combined group column: å…±æœ‰C62å–2=1891+62=1953 distinct pairs
pair_df$cluster_group <- apply(pair_df, 1, function(row) {
  sorted_row <- sort(unlist(c(row["cluster_1"], row["cluster_2"])), 
                     na.last = TRUE,
                     method = "radix",
                     decreasing = FALSE,
                     index.return = TRUE)
  sorted_cluster <- paste(sorted_row$x, collapse = "_")
  return(sorted_cluster)
})

# Calculate rb average
rb_cluster <- pair_df %>%
  group_by(cluster_group) %>%
  summarize(count = n(), mean_rb_perc = mean(rb) * 100)

# Create a symmetric cluster_group column
rb_cluster <- rb_cluster %>%
  mutate(cluster_group_symmetric = paste(substr(cluster_group, 4, 5), substr(cluster_group, 1, 2), sep = "_"))

# Combine the data for symmetric pairs
rb_cluster_combined <- bind_rows(rb_cluster, mutate(rb_cluster, cluster_group = cluster_group_symmetric))
rb_cluster_combined %<>%  
  distinct(cluster_group, .keep_all = TRUE) %<>%
  separate(cluster_group, into = c("x_axis", "y_axis"), sep = "_")

rb_cluster_matrix <- acast(rb_cluster_combined, x_axis ~ y_axis, value.var = "mean_rb_perc")

matrix_to_longformat <- function(mat) {
  as.data.frame(mat) |>
    tibble::rownames_to_column("cluster.x") |>
    tidyr::pivot_longer(-cluster.x, names_to = "cluster.y", values_to = "value")
}
to_plot <- matrix_to_longformat(rb_cluster_matrix)
hc <- hclust(as.dist(1 - rb_cluster_matrix))
order = hc$order
clustered_levels = colnames(rb_cluster_matrix)[order]

to_plot <- to_plot |>
  dplyr::mutate(cluster.x = forcats::fct_relevel(cluster.x, clustered_levels),
                cluster.y = forcats::fct_relevel(cluster.y, clustered_levels))

### Plot symmetric heatmap of mean rb
ggplot(to_plot , 
       aes(x = cluster.x, y = cluster.y, fill = value)) +
  geom_tile(color = "darkgray") +
  scale_fill_distiller(name = "mean rb %", palette = "RdYlBu") +
  theme_minimal() +
  theme(
    axis.line = element_blank(),        # Remove axis lines
    panel.grid.major = element_blank(),  # Remove major grid lines
    panel.grid.minor = element_blank(),  # Remove minor grid lines
    panel.border = element_blank()      # Remove panel border
  ) +
  xlab("") +
  ylab("")

```
***Network plot for clustered samples only***
```{r rb cluster network, echo=FALSE, warning = FALSE, message= FALSE}
# Input grouping files
setGroupsFromFile <- function(dcifer_list, filename)
{
  thisData <- read.csv(filename)
  group_ids <- as.vector(thisData[,1])
  group <- as.vector(thisData[,2])
  dcifer_list$group <- group
  if(!all(group_ids==dcifer_list$id)){
    print("Warning: IDs in group file don't match those on the model.")
    print(group_ids)
  }
  return(dcifer_list)
}

# Set group labels
setGroupLabels <- function(dcifer_list, filename){
  thisData <- read.csv(filename)
  labels <- as.vector(thisData[,2])
  dcifer_list$group_label <- labels
  return(dcifer_list)
}

# Set group colors
setGroupColours <- function(dcifer_list, filename){
  thisData <- read.csv(filename)
  colours <- as.vector(thisData[,3])
  dcifer_list$group_color <- colours
  return(dcifer_list)
}

GroupColour <- function(dcifer_list, group_label){
  index <- match(group_label, dcifer_list$group_label)
  if (is.na(index)) return ("white")
  return(dcifer_list$group_color[[index]])
}


# Cluster plot with grouping as vertex color
plotClusterGroup <- function(dcifer_list, level=0.5, alpha=0.05, vSize=2, thick=2, vFontSize=.5, labelOffset=1, legend_x=1, legend_y=1, group_name='Group', show_legend=TRUE, vertex_border_color='black', vertex_border_width=1, vertex_label=FALSE)
{
  edges <- NULL
  wgts <- NULL
  vcolours <- NULL
  isolates <- dcifer_list$id
  for (i in seq(length(dcifer_list$id)-1)){
    for (j in seq(i+1, length(dcifer_list$id))){
      if (dcifer_list$relatedness[i,j]>=level){
        if(dcifer_list$pvalue[i,j] < alpha){
          edges <- c(edges, dcifer_list$id[[i]], dcifer_list$id[[j]])
          wgts <- c(wgts, thick*dcifer_list$relatedness[i,j])
          isolates <- isolates[isolates != dcifer_list$id[[i]]]
          isolates <- isolates[isolates != dcifer_list$id[[j]]]
        }
      }
    }
  }
  
  gtitle <- paste0('Cluster plot for relatedness >= ',level, ' , by ', group_name)
  cgraph <- igraph::graph(edges=edges, isolates=isolates, directed=F)
  
  # Assign vertex colors
  for (c in 1:length(V(cgraph))){
    #since the names in the first column are only a part of all the nodes check if it belongs to that sublist
    if(V(cgraph)$name[c] %in% dcifer_list$id) {
      #then find the first occurrence of that name in the list and get its related color
      #assign it to that node
      V(cgraph)$color[c] <- as.character(dcifer_list$group_color[which(dcifer_list$id==V(cgraph)$name[c])[1]])
    }
    #otherwise the node will be white 
    else {
      V(cgraph)$color[c] <- "white"
    }
  }

  # Create a data frame for the legend with labels and corresponding colors
  legend_data <- data.frame(label = c("AG", "LO", "MZ", "CT", "LE", "PR"),
  color = c("red","blue","green","yellow", "purple", "grey"))
  
  igraph::E(cgraph)$weight <- wgts
  
  # Adjust the vertex border size and color
  V(cgraph)$size <- vSize
  V(cgraph)$border.color <- vertex_border_color
  V(cgraph)$border.width <- vertex_border_width
  
  plot(cgraph, edge.width=igraph::E(cgraph)$weight, vertex.size=V(cgraph)$size, 
       vertex.color=igraph::V(cgraph)$color, vertex.shape=igraph::V(cgraph)$shape, 
       vertex.label.cex=vFontSize, vertex.label.dist=labelOffset, 
       vertex.label = ifelse(vertex_label, V(cgraph)$name, NA),
       vertex.frame.color = V(cgraph)$border.color,
       vertex.frame.width = V(cgraph)$border.width,
       main=gtitle, frame=TRUE)
  
  if (show_legend) {
    coord <- par("usr")
    graphics::legend("topright",  # Adjusted to right for right side
                     legend=legend_data$label,
                     fill=legend_data$color,
                     title=group_name,
                     xjust = legend_x, yjust = legend_y)
  }
  
  return(cgraph)
} 


# Extract a dcifer_sublist by year
selected_ids <- sort(cluster_df$sampleID)
selected_indices <- match(selected_ids, dcifer_list$id)

dcifer_sublist <- list(
  id = dcifer_list$id[selected_indices],
  relatedness = dcifer_list$relatedness[selected_indices, selected_indices],
  pvalue = dcifer_list$pvalue[selected_indices, selected_indices]
)

new_meta_select <- new_meta %>% select(sampleID, new_year, area)

filename <- 'C:/Users/User1/SynologyDrive/UCSF work/STP data/ParagonV4/Cluster_plot/New_time_info.csv'
dcifer_sublist <- setGroupsFromFile(dcifer_sublist, filename)
dcifer_sublist <- setGroupColours(dcifer_sublist, filename)
dcifer_sublist <- setGroupLabels(dcifer_sublist, filename)

plotClusterGroup(dcifer_sublist, level=0.9, alpha=0.05, 
                                 vSize=1.4, thick=1, show_legend=F, group_name='Year', 
                                 vertex_border_color='grey5', vertex_border_width=0.8, vertex_label=F)


filename <- 'C:/Users/User1/SynologyDrive/UCSF work/STP data/ParagonV4/Cluster_plot/New_district_info.csv'
dcifer_sublist <- setGroupsFromFile(dcifer_sublist, filename)
dcifer_sublist <- setGroupColours(dcifer_sublist, filename)
dcifer_sublist <- setGroupLabels(dcifer_sublist, filename)

plotClusterGroup(dcifer_sublist, level=0.9, alpha=0.05, 
                 vSize=1.4, thick=1, show_legend=T, group_name='District', 
                 vertex_border_color='grey5', vertex_border_width=0.8, vertex_label=F)

```


**Regression and correlation analysis**
```{r regression analysis, echo=FALSE, warning = FALSE, message= FALSE}

### Input data
new_meta_lr <- new_meta %>% select(sampleID, post_coi_mean, post_effective_coi_mean,
                                   post_relatedness_mean, qPCR_Quantity, District,
                                   Location_rank, Age, Sex, Month, Treatment,
                                   infection, area, new_year, season)

new_meta_lr$Location_rank <- as.factor(new_meta_lr$Location_rank)
new_meta_lr$Location_rank <- relevel(new_meta_lr$Location_rank, ref = "Q2")

new_meta_lr %<>% mutate(ACT = ifelse(Treatment != "Quinine", 1, 0))

new_meta_lr %<>% mutate(poly = ifelse(infection == "poly", 1, 0), age_above5 = ifelse(Age > 5, 1, 0)) %>%
  mutate(area_level = case_when(
    District == "AG" ~ "H",
    District %in% c("MZ", "LO") ~ "M",
    TRUE ~ "L"
  ))

new_meta_lr %<>% mutate(Season = ifelse(Month %in% c(6:9), "Dry", "Rain"))

### Linear regression models
# MOI
moi_lr <- lm(post_coi_mean ~ log10(qPCR_Quantity) + area + Location_rank + age_above5 + Sex +
          ACT + new_year + Season, data = new_meta_lr)
summary(moi_lr)

# eMOI
emoi_lr <- lm(post_effective_coi_mean ~ log10(qPCR_Quantity) + area + Location_rank + age_above5 + Sex + ACT + new_year + Season, data = new_meta_lr)
summary(emoi_lr)

# rw
rw_lr <- lm(post_relatedness_mean ~ log10(qPCR_Quantity) + area + Location_rank + Age + Sex +
          ACT + new_year + Season, data = new_meta_lr)
summary(rw_lr)

### Logistic regression models
# Polyclonal
new_meta_lr %<>% mutate(poly = ifelse(infection == "poly", 1, 0), age_above5 = ifelse(Age > 5, 1, 0)) %>%
  mutate(area_level = case_when(
    District == "AG" ~ "H",
    District %in% c("MZ", "LO") ~ "M",
    TRUE ~ "L"
  ))

new_meta_lr$area_level <- as.factor(new_meta_lr$area_level)
new_meta_lr$area_level  <- relevel(new_meta_lr$area_level, ref = "L")

poly_glm <- glm(poly ~ log10(qPCR_Quantity) + area + Location_rank + age_above5 + Sex +
              ACT + new_year + Season + post_coi_mean, data = new_meta_lr)
summary(poly_glm)
round(exp(cbind(coef(poly_glm), confint.default(poly_glm))),2)

# Clustered
new_meta_lr %<>% mutate(clustered = ifelse(sampleID %in% cluster_df$sampleID, 1, 0))
cluster_glm <- glm(clustered ~ log10(qPCR_Quantity) + area + Location_rank + age_above5 + Sex +
                  ACT + new_year, data = new_meta_lr)
summary(cluster_glm)
round(exp(cbind(coef(cluster_glm), confint.default(cluster_glm))),2)

new_meta_lr %<>% mutate(noncluster = ifelse(sampleID %in% cluster_df$sampleID, 0, 1))
noncluster_glm <- glm(noncluster ~ log10(qPCR_Quantity) + area + Location_rank + age_above5 + Sex +
                  ACT + new_year, data = new_meta_lr)
summary(noncluster_glm)
round(exp(cbind(coef(cluster_glm), confint.default(cluster_glm))),2)

```
