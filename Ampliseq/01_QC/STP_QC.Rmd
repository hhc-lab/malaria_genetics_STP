---
title: "QC"
author: "Angie Chen"
date: '2024-01-30'
output: 
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
---

**Load libraries and working directory**
```{r load libraries, echo=FALSE, warning = FALSE, message= FALSE}

library(dplyr)
library(magrittr)
library(ggplot2)
library(reshape2)
library(tidyr)
library(tidyverse)
library(stringr)
library(tools)
library(purrr)
library(parallel)
library(data.table)
library(vctrs)
library(plotly)
library(trelliscopejs)
library(shiny)
library(htmltools)
library(htmlwidgets)
library(viridis)
library(gridExtra)
library(ggrepel)
library(readxl)
library(scales)

```


# Dimer check - Use sample_coverage files
```{r dimer check, echo=FALSE, warning = FALSE, message= FALSE}

# Merge all sample coverage files into a "dimer_check" summary file

dimer_check <- read.csv("C:/Users/User1/SynologyDrive/STP_paper_writing/Github_data_script/Ampliseq/01_QC/dimer_check.csv", header = T) # Change to your file path


# Plot total reads make into amplicons (facet by run)
plot_dimer <- function(dimer_check) {
  cols <- alpha(c("Sample" = "lightcoral", "NC" = "olivedrab3", "PC" = "cornflowerblue"), alpha =0.8)
  g <- ggplot(dimer_check, aes(x=reorder(SampleID, -Input), y=Input)) + 
  geom_col(fill = "grey") +
  geom_col(data = dimer_check, aes(y = Amplicons, colour = group, fill = group)) +
  theme_bw() +
  scale_y_log10() +
  scale_fill_manual(values = cols, aesthetics = c("colour", "fill")) +
  ylab("Total reads") + xlab("SampleID") +
  theme(axis.text = element_text(size = 10), 
        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1, size = 4)) +
  facet_wrap(~run, scales = "free_x") + #Remove this line if you only have single run or without this info
  ggtitle("How many total reads make it to amplicons? (facet by run)")
  
  g
}

plot_dimer(dimer_check)


# Plot amplicon proportion (amplicons/input)
plot_amplicon_perc <- function(dimer_check) {
  cols <- alpha(c("Sample" = "lightcoral", "NC" = "olivedrab3", "PC" = "cornflowerblue"), alpha =0.8)
  g <- ggplot(dimer_check) +
  geom_col(aes(x = reorder(SampleID, -perc_amplicons), y= perc_amplicons, colour = group, fill = group)) + 
  ylab("Proportion of reads that are amplicons") + xlab("SampleID") + 
  theme_bw() +
  scale_fill_manual(values = cols, aesthetics = c("colour", "fill")) +
  theme(axis.text = element_text(size = 10), 
        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1, size = 4)) + 
  scale_y_continuous(limits = c(0,1), expand = c(0, 0)) +
  facet_wrap(~run, scales = "free_x") + #Remove this line if you only have single run or without this info
  ggtitle("What proportion of inputs make it to amplicons? (facet by run)")
  
  g
}

plot_amplicon_perc(dimer_check)

# Report dimer % in each run
dimer_check %>%
  group_by(run) %>%
  summarise(dimer_percent = 100*(sum(Input)-sum(`No.Dimers`))/sum(Input))

```


# Preview data structure

**Merge allele, gene (amplicon info), and meta data**
```{r merge allele-gene-meta data, echo=FALSE, warning = FALSE, message= FALSE}

# Import data
allele <- read.csv("C:/Users/User1/SynologyDrive/STP_paper_writing/Github_data_script/Ampliseq/01_QC/allele_data.csv", header = T)
gene <- read.csv("C:/Users/User1/SynologyDrive/STP_paper_writing/Github_data_script/Ampliseq/01_QC/gene_data.csv", header = T)
meta <- read.csv("C:/Users/User1/SynologyDrive/STP_paper_writing/Github_data_script/Ampliseq/01_QC/meta_data.csv", header = T)


# Merge lists
data <- merge(allele, gene, by = "locus")
data <- merge(data, meta, by = "sampleID")

```


**Preview raw data - sample size, loci numbers, allele numbers**
```{r preview data info, echo=FALSE, warning = FALSE, message= FALSE}

# Overall info of the data
sample_size <- n_distinct(data$sampleID)
print(sprintf("Sample size= %s", sample_size))

locus_no <- n_distinct(data$locus)
print(sprintf("All locus = %s", locus_no))

# Allele range in each sample
print(sprintf("%s to %s alleles per locus per sample",
              min(data$n.alleles), max(data$n.alleles)))

# Locus with mono/poly alleles in each sample
clone <- data %>% 
  group_by(sampleID, locus) %>% 
  summarise(total_alleles = n()) %>%
  mutate(Clone = ifelse(total_alleles == 1, "Mono", "Poly"))
clone %<>% group_by(sampleID) %>% count(Clone)
clone_wide <- tidyr::spread(clone, Clone, n)
clone_wide[is.na(clone_wide)] <- 0
clone_wide %<>% mutate(Total_alleles = Mono + Poly) %>% 
  mutate(Mono_prop = Mono/Total_alleles) %>% 
  mutate(Poly_prop = Poly/Total_alleles)
print(sprintf("Mean of total loci counts = %s, Mean prop. of monoclonal loci = %s, Mean prop. of polyclonal loci = %s",
              round(mean(clone_wide$Total_alleles),2), 
              round(mean(clone_wide$Mono_prop),2), 
              round(mean(clone_wide$Poly_prop),2)))

# Plot allele counts per amplicon
plot_total_alleles <- function(data){
  # Data
  allele_table <- data %>% 
  group_by(locus) %>% 
  summarize(total_alleles = n_distinct(allele.type)) %>% 
  arrange(-total_alleles)
  
  q95 <- quantile(allele_table$total_alleles, 0.95)
  allele_table %<>% mutate(alleles_over_q95 = ifelse(total_alleles > q95, "Y", "N"))
  
  # Plot
  g <- allele_table %>%
    ggplot(aes(x = locus, y = total_alleles, color = alleles_over_q95)) +
    geom_point() +
    theme(axis.text.x = element_text(angle = 90, hjust = 0, size = 5)) +
    scale_color_hue(direction = -1) 
  
  g
}
ggplotly(plot_total_alleles(data))

```


**Preview raw data - Plate map, Detect contamination and Check balanced**
```{r plate map & contamination, echo=FALSE, warning = FALSE, message= FALSE}

### Plate map 

plot_plate_map <- function (data) {
  # Extract row/col from position in data
data %<>%
  mutate(col = str_extract(Lib_plate_pos, "\\d+")) %>%
  mutate(row = str_extract(Lib_plate_pos, "[A-Z]+"))
  
map_all_reads <- data %>%
  group_by(sampleID, row, col, Lib_plate) %>% 
  summarise(mean_reads = mean(reads)) %>%
  mutate(group = case_when(
    grepl("NC", sampleID) ~ "Negative", # Change identifier for your negative ctrls
    grepl("PC", sampleID) ~ "Positive", # Change identifier for your positive ctrls
    TRUE ~ "Sample"))
  
  map_all_reads$row <- as.factor(map_all_reads$row)
  map_all_reads$col <- as.factor(map_all_reads$col)
  
  # Heatmap setup
  heat_lab <- c("1","10","30", "100", "300", "1000", "3000")
  heat_break <- c(1, 10, 30, 100, 300, 1000, 3000)

  # Plot
g <- map_all_reads %>%
  filter(!is.na(col)) %>%
  ggplot(aes(x = col, y = row, text = paste(sampleID))) +
  geom_tile(aes(fill = mean_reads, color = group, size = group)) +
  scale_fill_gradient(low = "black", high = "yellow", trans = "log",
                      labels = heat_lab, breaks = heat_break) +
  scale_colour_manual("group", values = c("red", "blue", "#00000000")) + 
  scale_size_manual("group", values = c(0, 1, 1)) +
  ylim(rev(levels(map_all_reads$row))) + 
  theme_bw() +
  theme(axis.title = element_blank()) +
  facet_wrap(~ Lib_plate)

 g
}

plot_plate_map(data)

```

**Check negative controls**
```{r negative controls, echo=FALSE, warning = FALSE, message= FALSE}

### 1. Use median or mean reads cutoffs to identify contaminated NC

## Use median reads cutoff
plot_nc_median <- function(data, med_cutoff = 5) {
  
  # Data
  data_nc <- data %>% filter(grepl("NC", sampleID)) #Change identifier for your neg. ctrls
  nc_reads <- data_nc %>% group_by(sampleID) %>% summarize(median = median(reads), 
                                                           mean = mean(reads), total = sum(reads))
  nc_reads %<>%
  mutate(Contamination = case_when(
    median > med_cutoff ~ "Yes",
    TRUE ~ "No")) 
  
  # Plot
  g <- nc_reads %>%
  ggplot(aes(x = sampleID, y = median, fill = Contamination)) +
  geom_bar(stat = "identity") +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 5)) +
  scale_y_continuous(name = "Median reads") +
  geom_hline(yintercept = med_cutoff, linetype = "dashed", color = "black", alpha = .5) +
  scale_fill_manual(values = c("gray40", "red"))
  
  g
}  

plot_nc_median(data, med_cutoff = 5)

## Use mean reads cutoff
plot_nc_mean <- function(data, mean_cutoff = 5) {
  
  # Data
  data_nc <- data %>% filter(grepl("NC", sampleID))
  nc_reads <- data_nc %>% group_by(sampleID) %>% summarize(median = median(reads), 
                                                           mean = mean(reads), total = sum(reads))
  nc_reads %<>%
  mutate(Contamination = case_when(
    mean > mean_cutoff ~ "Yes",
    TRUE ~ "No")) 
  
  # Plot
  g <- nc_reads %>%
  ggplot(aes(x = sampleID, y = mean, fill = Contamination)) +
  geom_bar(stat = "identity") +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 5)) +
  scale_y_continuous(name = "Mean reads") +
  geom_hline(yintercept = mean_cutoff, linetype = "dashed", color = "black", alpha = .5) +
  scale_fill_manual(values = c("gray40", "red"))
  
  g
}  

plot_nc_mean(data, mean_cutoff = 5)


### 2. How do neg.ctrls compare for each sequence run?
plot_nc_reads_run <- function(data) {
  # Data
  data_nc_loci <- data %>% 
  filter(grepl("NC", sampleID)) %>%
  group_by(sampleID, locus, Run) %>% 
  # you have to summarize the reads over the locus first 
  summarize(reads = sum(reads)) %>% 
  ungroup() 
  
  # Plot
  g <- ggplot(data = data_nc_loci, aes(x = reads)) + 
  geom_histogram() +
  geom_vline(xintercept = 100, linetype='dotted', col = 'darkred') +
  xlab("Number of reads at locus") +
  ylab("Loci count") +
  facet_wrap(~Run) + 
  ggtitle("How do neg.ctrls compare for each sequence run?")
  
  g
}

plot_nc_reads_run(data)

# List neg. ctrls with > 100 reads/allele & identify contaminated runs
data %>% 
  filter(grepl("NC", sampleID)) %>%
  group_by(sampleID, locus, Run) %>% 
  summarize(reads = sum(reads)) %>% 
  ungroup() %>% 
  filter(reads > 100) %>% 
  arrange(reads) %>%
  distinct(sampleID)

## 3. What is the mean number of neg.ctrl reads, "by pool"? 
plot_nc_pool <- function(data) {
  
   # Data
  loci_neg <- data %>% 
  filter(grepl("NC", sampleID)) %>%
  group_by(sampleID, locus, Run) %>% 
  summarize(reads = sum(reads)) %>% 
  ungroup() %>% 
  group_by(locus) %>% 
  summarise(reads = mean(reads)) %>%
  mutate(pool = sapply(strsplit(locus,"-"),tail,1))
  
  #Plot
  g <- ggplot(loci_neg, aes(y=reads, x=locus)) +
  geom_bar(position="dodge", stat="identity") +
  geom_hline(yintercept = 100, linetype='dotted', col = 'darkred') +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1, size = 5)) +
  ggtitle("What is the mean number of neg.ctrl reads, by pool?") + 
  facet_wrap(~pool, scales = "free_x")
  
  g
}  

plot_nc_pool(data)

## 4. Where did the reads of NC come from? 

# Use P01 one contaminated NC as example
P01_nc_allele <- data %>% filter(sampleID == "M07_NC-D05") %>% pull(allele.type) #Extract allele data from the specified contaminated NC
P01 <- data %>% filter(Lib_plate == "P01") %>%
  mutate(nc_allele = ifelse(allele.type %in% P01_nc_allele, 1, 0)) #Extract the contaminated plate info

# Proportion of alleles present in that contaminated NC 
P01_norm <- P01 %>% group_by(sampleID, Lib_plate_pos, nc_allele) %>% summarize(count = n())
P01_norm <- P01_norm %>% group_by(sampleID) %>% mutate(total_allele = sum(count))
P01_norm <- P01_norm %>% mutate(prop_nc_allele = count/total_allele)
P01_norm %<>% 
  mutate(col = str_extract(Lib_plate_pos, "\\d+")) %>%
  mutate(row = str_extract(Lib_plate_pos, "[A-Z]+")) %>%
  mutate(group = case_when(
    grepl("NC", sampleID) ~ "Negative",
    grepl("PC", sampleID) ~ "Positive",
    TRUE ~ "Sample"))

P01_norm$row <- as.factor(P01_norm$row)
P01_norm$col <- as.factor(P01_norm$col)

heat_lab <- seq(0, 1, 0.1)
heat_break <- seq(0, 1, 0.1)

P01_norm %>%
  ggplot(aes(x = col, y = row, text = paste(sampleID))) +
  geom_tile(aes(fill = prop_nc_allele, color = group), size = 1.5) +
  scale_fill_gradient(low = "black", high = "yellow", trans = "log",
                      breaks = heat_break, labels = heat_lab) +
  scale_colour_manual("group", values = c("red", "blue", "white")) + 
  scale_size_manual("group", values = c(0, 1, 1)) +
  ylim(rev(levels(P01_norm$row))) + 
  theme_bw() +
  theme(axis.title = element_blank()) +
  ggtitle("P01")

# No. of nc reads on P01
P01_nc_reads <- P01 %>% group_by(sampleID, nc_allele, Lib_plate_pos) %>% 
  summarize(mean_reads = round(mean(reads)), reads = sum(reads)) %>%
  mutate(total_reads = sum(reads)) %>% mutate(prop_nc_reads = reads/total_reads) %>%
  mutate(col = str_extract(Lib_plate_pos, "//d+")) %>%
  mutate(row = str_extract(Lib_plate_pos, "[A-Z]+")) %>%
  mutate(group = case_when(
    grepl("NC", sampleID) ~ "Negative",
    grepl("PC", sampleID) ~ "Positive",
    TRUE ~ "Sample"))
P01_nc_reads %>%
  filter(nc_allele == 1) %>%
ggplot(aes(x=sampleID, y=log10(mean_reads), color = group)) + 
  geom_point() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0, hjust = 1, size = 6)) +
  geom_hline(aes(yintercept = 2), color = "red", linetype='dashed') +
  ggtitle("P01")

```


**Check positive controls**
```{r positive controls, echo=FALSE, warning = FALSE, message= FALSE}

plot_pc_clones <- function(data){
  # Data
  
  # Suppose using same PCs (3D7, monoclonal) across plates/runs
data_pc <- data %>% filter(grepl("PC", sampleID)) #Change identifier for your pos. ctrls
positives <- data_pc %>% 
  group_by(sampleID, locus) %>%
  mutate(read_fraction = 100*reads/sum(reads))%>%
  mutate(n.alleles = n()) %>%
  mutate(Clone = ifelse(n.alleles == 1, "Mono", "Poly"))
  
  ## Look at clonality
pc_clone <- data %>% 
  filter(grepl("PC", sampleID)) %>% 
  group_by(sampleID, locus, Run) %>% 
  summarise(total_alleles = n()) %>%
  mutate(Clone = ifelse(total_alleles == 1, "Mono", "Poly"))
pc_clone <- pc_clone %>% 
  group_by(sampleID, Run) %>% 
  count(Clone)

  # Plot
    g <- pc_clone %>%
    ggplot(aes(x= sampleID, y= n)) +
    geom_col(aes(fill = Clone)) +
    theme(axis.text.y = element_text(size = 8), axis.text.x = element_text(angle = 90, size =7)) +
    scale_y_continuous(name = "Locus No.", breaks = seq(0,200, by = 50)) 
  
    g
}

ggplotly(plot_pc_clones(data))


# Check which loci have > 1 allele in PCs

plot_pc_polyclonal_loci <- function(data){
  
data_pc <- data %>% filter(grepl("PC", sampleID)) #Change identifier for your pos. ctrls
positives <- data_pc %>% 
  group_by(sampleID, locus) %>%
  mutate(read_fraction = 100*reads/sum(reads))%>%
  mutate(n.alleles = n()) %>%
  mutate(Clone = ifelse(n.alleles == 1, "Mono", "Poly"))
pc_poly_allele <- positives %>% filter(n.alleles > 1)
g <- pc_poly_allele %>%
  ggplot() +
  geom_point(aes(x = norm.reads.locus, y = log10(reads), color = locus)) +
  geom_hline(aes(yintercept = 2), color = "black", linetype='dashed')

g

}

ggplotly(plot_pc_polyclonal_loci(data))

# Check consistency in PCs (3D7)
allele_pc <- data %>% filter(grepl("PC", sampleID)) %>%
  group_by(sampleID, locus, allele.type, reads, Run) %>%
  summarize()

allele_pc <- allele_pc %>%
  group_by(locus, allele.type) %>%
  mutate(duplicated = n() > 1) %>%
  ungroup()

pc_dup_prop <- allele_pc %>%
  group_by(sampleID) %>%
  summarize(pc_dup_prop  = sum(duplicated == TRUE) / n())

print(pc_dup_prop) # Those with < 90% consistency are problematic PCs 

```



**Remove contaminated runs**
```{r remove contaminated runs, echo=FALSE, warning = FALSE, message= FALSE}

### Remove contaminated runs
filtered_data <- data %>% filter(! Run %in% c("M07", "M09", "M10", "M13", "M15")) #Input the identified contaminated run names

# Overall info of the data after removing contaminated runs
sample_size <- n_distinct(filtered_data$sampleID)
print(sprintf("Sample size= %s Retained prop. = %s", sample_size, round(sample_size/n_distinct(data$sampleID), 2)))

locus_no <- n_distinct(filtered_data$locus)
print(sprintf("All locus = %s", locus_no))

allele_table <- filtered_data %>% 
  group_by(locus) %>% 
  summarize(total_alleles = n_distinct(allele.type)) %>% 
  arrange(-total_alleles)

# Allele range in each sample
print(sprintf("%s to %s alleles per locus per sample",
              min(filtered_data$n.alleles), max(filtered_data$n.alleles)))

```


# Data QC and filtering 
(1) Filter out bad-quality samples and possible false positive alleles (off-targets, low-abundance)
(2) Make moire input file

**Step 1. Total reads**
```{r filter total reads, echo=FALSE, warning = FALSE, message= FALSE}

### Step 1: Check total reads of samples

## Plot total reads distribution - NC, PC, Samples
plot_reads_dist <- function(data){
  
  #Data
  # Summarize total reads
 reads_table <- data %>% 
  distinct(sampleID, locus, allele.type, .keep_all = TRUE) %>%
  group_by(sampleID) %>% 
  summarize(Total_reads = sum(reads)) %>% 
  arrange(Total_reads) 

  # Extract data from controls
sampleID <- unique(data$sampleID) 
 pc <- sampleID[grepl("PC", sampleID)] #Change identifier for your pos. ctrls
 nc <- sampleID[grepl("NC", sampleID)] #Change identifier for your neg. ctrls
 controls <- c(pc, nc) 
 data_pc <- data %>% filter(sampleID %in% pc)
 data_nc <- data %>% filter(sampleID %in% nc) 

  reads_table %<>%
  mutate(label = case_when(
    sampleID %in% pc ~ "PC",
    sampleID %in% nc ~ "NC",
    TRUE ~ "Sample"))
  
  #Plot
  g <- ggplot(reads_table, aes(x = log10(Total_reads), fill = label)) +
  geom_density(alpha = .5) +
  ggtitle("Total reads distribution")
  
  g
}

plot_reads_dist(filtered_data)

## Visualize samples with low reads: Pool1A5+2 has 241 loci, at least each loci has 100 reads, so total reads cutoff will be 241*100

plot_reads_cutoff <- function(data, loci = 241, reads_cutoff = 100){
  #data
  # Summarize total reads
 reads_table <- data %>% 
  distinct(sampleID, locus, allele.type, .keep_all = TRUE) %>%
  group_by(sampleID) %>% 
  summarize(Total_reads = sum(reads)) %>% 
  arrange(Total_reads) 

  # Extract data from controls
sampleID <- unique(data$sampleID) 
 pc <- sampleID[grepl("PC", sampleID)] #Change identifier for your pos. ctrls
 nc <- sampleID[grepl("NC", sampleID)] #Change identifier for your neg. ctrls
 controls <- c(pc, nc) 
 data_pc <- data %>% filter(sampleID %in% pc)
 data_nc <- data %>% filter(sampleID %in% nc) 

  reads_table %<>%
  mutate(label = case_when(
    sampleID %in% pc ~ "PC",
    sampleID %in% nc ~ "NC",
    TRUE ~ "Sample"))
  
  # Set up reads criterion
  reads_criterion <- loci*reads_cutoff
  sample_low_reads <- reads_table %>% filter(! sampleID %in% controls) %>% 
    filter(Total_reads < reads_criterion) %>% pull(sampleID)
  
  # Make plotting df
reads_table %<>%
  mutate(QC = case_when(
    sampleID %in% pc ~ "Positive controls",
    sampleID %in% nc ~ "Negative controls",
    sampleID %in% sample_low_reads ~ "Low-reads samples",
    TRUE ~ "QC-passed samples")) %>%
  mutate(color = case_when(
    sampleID %in% pc ~ "red",
    sampleID %in% nc ~ "green",
    sampleID %in% sample_low_reads ~ "gray",
    TRUE ~ "black")) %>%
  arrange(factor(QC, levels = c("Negative controls", "Low-reads samples", "Positive controls", "QC-passed samples"))) 

color_axis <- reads_table$color[order(reads_table$sampleID)]
color_fill <- c("Positive controls" = "red", "Negative controls" = "green", "Low-reads samples" = "gray", "QC-passed samples" = "black")

level_order <- reads_table$sampleID

 # Plot
 g <- reads_table %>%
  ggplot(aes(x = factor(sampleID, level = level_order), y = log10(Total_reads), fill = QC)) +
  geom_bar(stat = "identity") + 
  coord_flip() + 
  scale_fill_manual(values = color_fill) +
  theme_classic() +
  theme(axis.text.y=element_blank()) +
  geom_hline(yintercept = log10(reads_criterion), linetype='dashed', color = 'red')+
  ylab("Log10 Total Reads") +
  xlab("sampleID") +
  ggtitle("Filter out samples with low-reads")
  
  g
}
  
ggplotly(plot_reads_cutoff(filtered_data, loci = 241, reads_cutoff = 100))


### Filter 2: Remove samples with low reads

remove_low_reads_samples <- function(data, loci = 241, reads_cutoff = 100){
  # Summarize total reads
  reads_table <- data %>% 
    distinct(sampleID, locus, allele.type, .keep_all = TRUE) %>%
    group_by(sampleID) %>% 
    summarize(Total_reads = sum(reads)) %>% 
    arrange(Total_reads) 

  # Extract data from controls
  sampleID <- unique(data$sampleID) 
  pc <- sampleID[grepl("PC", sampleID)] # Change identifier for your pos. ctrls
  nc <- sampleID[grepl("NC", sampleID)] # Change identifier for your neg. ctrls
  controls <- c(pc, nc) 
  data_pc <- data %>% filter(sampleID %in% pc)
  data_nc <- data %>% filter(sampleID %in% nc) 

  reads_table <- reads_table %>%
    mutate(label = case_when(
      sampleID %in% pc ~ "PC",
      sampleID %in% nc ~ "NC",
      TRUE ~ "Sample"))
  
  # Set up reads criterion
  reads_criterion <- loci * reads_cutoff
  sample_low_reads <- reads_table %>% filter(! sampleID %in% controls) %>% 
    filter(Total_reads < reads_criterion) %>% pull(sampleID)

  clean_data <- data %>% filter(! sampleID %in% unique(c(controls, sample_low_reads))) 
  sample_size <- n_distinct(clean_data$sampleID)
  clean_data_info <- sprintf("Step 1 - Sample size after removing samples with insufficient reads = %s, Retained prop. = %s", sample_size, round(sample_size/n_distinct(data$sampleID), 2))

  return(list(clean_data = clean_data, clean_data_info = clean_data_info, removed_sampleID = sample_low_reads))
}

# Example usage:
result <- remove_low_reads_samples(filtered_data)
filtered_data1 <- result$clean_data  # This will give you the data after removing low-reads samples
print(result$clean_data_info)  # This will print the information of filtered data compared to original input data
sample_low_reads <- print(result$removed_sampleID) # This will print the information of removed sampleID

```


**Step 2. Loci coverage** 
```{r filter loci coverage, echo=FALSE, warning = FALSE, message= FALSE}

### Step 2: Check loci coverage

## Total loci distribution and summary by RUN

plot_loci_dist <- function(data){

# Data    
clone <- data %>%
  group_by(Run, sampleID, locus) %>% 
  summarise(total_loci = n()) %>%
  mutate(Clone = ifelse(total_loci == 1, "Mono", "Poly"))
clone %<>% group_by(sampleID, Run) %>% count(Clone)

clone_wide <- clone %>% pivot_wider(names_from = Clone, values_from = n)
clone_wide[is.na(clone_wide)] <- 0
clone_wide %<>% mutate(Total_loci = Mono + Poly) %>% 
  mutate(Mono_prop = Mono/Total_loci) %>% 
  mutate(Poly_prop = Poly/Total_loci) %>%
  arrange(- Poly_prop)

clone_wide_select <- clone_wide %>% select(sampleID, Poly_prop) 
clone <- merge(clone, clone_wide_select, by = "sampleID")
clone %<>% arrange(- Poly_prop) %>% select(- Run.y) %>% rename(Run = Run.x)

# Plot
g <- ggplot(clone_wide, aes(x = Total_loci)) +
  geom_histogram() +
  scale_x_continuous(breaks = seq(0, 300, 25)) +
  facet_wrap(~Run) # M3~M7 used 1AB+2 (total loci = 276), the rest used 1A5+2 (total loci = 241)

g

}

plot_loci_dist(filtered_data1)

### Visualize samples with insufficient coverage of loci

plot_loci_cutoff <- function(data, loci = 241, perc_covered = 0.8){

# Data    
clone <- data %>%
  group_by(Run, sampleID, locus) %>% 
  summarise(total_loci = n()) %>%
  mutate(Clone = ifelse(total_loci == 1, "Mono", "Poly"))
clone %<>% group_by(sampleID, Run) %>% count(Clone)

clone_wide <- clone %>% pivot_wider(names_from = Clone, values_from = n)
clone_wide[is.na(clone_wide)] <- 0
clone_wide %<>% mutate(Total_loci = Mono + Poly) %>% 
  mutate(Mono_prop = Mono/Total_loci) %>% 
  mutate(Poly_prop = Poly/Total_loci) %>%
  arrange(- Poly_prop)

clone_wide_select <- clone_wide %>% select(sampleID, Poly_prop) 
clone <- merge(clone, clone_wide_select, by = "sampleID")
clone %<>% arrange(- Poly_prop) %>% select(- Run.y) %>% rename(Run = Run.x)

# Set up loci criterion
loci_criterion <- round(loci*perc_covered)

sample_less_loci <- clone %>%
  group_by(sampleID) %>%
  summarize(total_loci = sum(n)) %>%
  filter(total_loci < loci_criterion) %>% 
  pull(sampleID)

# Plot
  g <- clone %>%
  ggplot(aes(x = reorder(sampleID, Poly_prop), y = n)) +
  geom_col(aes(fill = Clone)) +
  theme(axis.text.y=element_blank()) +
  coord_flip()+
  scale_y_continuous(name = "No. of locus", breaks = seq(0,200, by = 50)) +
  geom_hline(yintercept = loci_criterion, linetype='dotted', col = 'black') +
  xlab("sampleID") +
  ggtitle("Filter out samples with insufficient loci coverage") 
  
  g
}

ggplotly(plot_loci_cutoff(filtered_data1, loci = 241, perc_covered = 0.8))


### Filter out samples with insufficient loci coverage
remove_low_loci_samples <- function(data, loci = 241, perc_covered = 0.8){
  
  # Data    
  clone <- data %>%
    group_by(Run, sampleID, locus) %>% 
    summarise(total_loci = n()) %>%
    mutate(Clone = ifelse(total_loci == 1, "Mono", "Poly"))
  clone %<>% group_by(sampleID, Run) %>% count(Clone)
  
  clone_wide <- clone %>% pivot_wider(names_from = Clone, values_from = n)
  clone_wide[is.na(clone_wide)] <- 0
  clone_wide %<>% mutate(Total_loci = Mono + Poly) %>% 
    mutate(Mono_prop = Mono/Total_loci) %>% 
    mutate(Poly_prop = Poly/Total_loci) %>%
    arrange(- Poly_prop)
  
  clone_wide_select <- clone_wide %>% select(sampleID, Poly_prop) 
  clone <- merge(clone, clone_wide_select, by = "sampleID")
  clone %<>% arrange(- Poly_prop) %>% select(- Run.y) %>% rename(Run = Run.x)
  
  # Set up loci criterion
  loci_criterion <- round(loci*perc_covered)
  sample_less_loci <- clone %>%
    group_by(sampleID) %>%
    summarize(total_loci = sum(n)) %>%
    filter(total_loci < loci_criterion) %>% 
    pull(sampleID)
  
  clean_data <- data %>% filter(! sampleID %in% sample_less_loci) 
  sample_size <- n_distinct(clean_data$sampleID)
  clean_data_info <- sprintf("Step 2 - Sample size after removing samples with insufficeint loci coverage = %s, Retained prop. = %s", sample_size, round(sample_size/n_distinct(data$sampleID), 2))
  
  
  return(list(clean_data = clean_data, clean_data_info = clean_data_info, removed_sampleID = sample_less_loci))
}

# Example usage:
result <- remove_low_loci_samples(filtered_data1)
filtered_data2 <- result$clean_data  # This will give you the data after removing low-loci-coverage samples
print(result$clean_data_info)  # This will print the information of filtered data compared to original input data
sample_less_loci <- print(result$removed_sampleID) # This will print the information of removed sampleID

```


**Step 3: Proportion of loci > 100 reads in samples**
```{r filter n100 proportion, echo=FALSE, warning = FALSE, message= FALSE}

### Calculate loci having 100 reads (n100) and plot n100 by gene categories

plot_n100_loci_cutoff <- function(data, n100_cutoff = 0.5){ 

  # Group by sample + loci category
locus_cov_100 <- data %>% 
  group_by(sampleID, locus, Category, Pool, Lib_condition) %>% 
  summarize(reads = sum(reads)) %>% 
  ungroup() 

 # Calculate n100 and n50 loci counts
locus_cov_100 %<>%
  group_by(sampleID, Category, Pool, Lib_condition) %>% 
  summarize(total_reads = sum(reads), n100 = sum(reads >= 100)) 
  
  # Normalization - calculate % loci with n100 or n50 (Species targets are not counted)
amp_cov_category_norm <- locus_cov_100 %>% 
  filter(Category != "Species") %>%
  mutate(norm_100 = case_when(
    Category == "Diversity" ~ n100/165,
    Category == "Resistance" &  grepl("1AB & 2", Lib_condition) ~ n100/55,
    Category == "Resistance" &  grepl("1A5 & 2", Lib_condition) ~ n100/38,
    Category == "Immune" &  grepl("1AB & 2", Lib_condition) ~ n100/15,
    Category == "Immune" & grepl("1A5 & 2", Lib_condition) ~ n100/5,
    Category == "Diagnostic" &  grepl("1AB & 2", Lib_condition) ~ n100/36,
    Category == "Diagnostic" & grepl("1A5 & 2", Lib_condition) ~ n100/30))
  
# Plot
  g <- ggplot(amp_cov_category_norm, aes(x=total_reads, y = norm_100)) +
  geom_point(aes(color = "red", alpha = 0.5)) +
  scale_x_log10() + 
  geom_hline(yintercept = n100_cutoff, linetype = "dashed", color = "black") +
  facet_wrap(~ Category) +
  ggtitle("Normalized prop. of loci with > 100 reads in each sample") +
  ylim(0,1) +
  ylab("Proportion of loci with >100 reads") +
  xlab("Total reads")
  
  g
}  

plot_n100_loci_cutoff(filtered_data2 , n100_cutoff = 0.5)


### Plot n100 proportion & sample retained

plot_n100_sample_cutoff <- function(data, n100_cutoff = 0.5){
  
  # Group by sample + loci category
locus_cov_100 <- data %>% 
  group_by(sampleID, locus, Category, Pool, Lib_condition) %>% 
  summarize(reads = sum(reads)) %>% 
  ungroup() 

n_table <- locus_cov_100 %>%
  filter(Category == "Diversity") %>%
  group_by(sampleID, locus) %>% 
  summarize(total_reads = sum(reads)) %>%
  mutate(n100 = ifelse(total_reads >= 100, 1, 0))

n_count <-  n_table  %>%
  group_by(sampleID) %>%
  summarise(
    n100_0_count = sum(n100 == 0),
    n100_1_count = sum(n100 == 1),
    n100_proportion = n100_1_count / n())

# Create a data frame to store the results
results <- data.frame(X = numeric(), SampleCount = numeric())

# Loop through different threshold values
for (X in 0:100) {
  filtered_data <- n_count %>%
    filter(n100_proportion >= (X / 100))  # Convert X to a proportion

  # Add X and the count of samples exceeding the threshold to the results data frame
  results <- rbind(results, data.frame(X = X, SampleCount = nrow(filtered_data)))
}

# Create the plot showing tradeoffs between n100 proportion & sample retained
g <- ggplot(results, aes(x = SampleCount, y = X)) +
  geom_line() +
  geom_hline(yintercept = n100_cutoff*100, linetype = "dashed", color = "black", alpha = .5) +
  labs(y = "Proportion of loci over 100 reads", x = "Sample count") +
  scale_x_continuous(breaks = seq(0, 1250, 100))

g

}

plot_n100_sample_cutoff(filtered_data2 , n100_cutoff = 0.5)


### Remove samples with too low n100
remove_n100_cutoff <- function(data, n100_cutoff = 0.5){
  # Group by sample + loci category
  locus_cov_100 <- data %>% 
    group_by(sampleID, locus, Category, Pool, Lib_condition) %>% 
    summarize(reads = sum(reads)) %>% 
    ungroup() 
  
  # Calculate n100 and n50 loci counts
  locus_cov_100 <- locus_cov_100 %>%
    group_by(sampleID, Category, Pool, Lib_condition) %>% 
    summarize(total_reads = sum(reads), n100 = sum(reads >= 100)) 
  
  # Normalization - calculate % loci with n100 or n50 (Species targets are not counted)
  amp_cov_category_norm <- locus_cov_100 %>% 
    filter(Category != "Species") %>%
    mutate(norm_100 = case_when(
      Category == "Diversity" ~ n100/165,
      Category == "Resistance" &  grepl("1AB & 2", Lib_condition) ~ n100/55,
      Category == "Resistance" &  grepl("1A5 & 2", Lib_condition) ~ n100/38,
      Category == "Immune" &  grepl("1AB & 2", Lib_condition) ~ n100/15,
      Category == "Immune" & grepl("1A5 & 2", Lib_condition) ~ n100/5,
      Category == "Diagnostic" &  grepl("1AB & 2", Lib_condition) ~ n100/36,
      Category == "Diagnostic" & grepl("1A5 & 2", Lib_condition) ~ n100/30))
  
  # Remove samples with diversity n100 < 50%
  sample_n100_fail <-  amp_cov_category_norm %>% filter(Category == "Diversity") %>% filter(norm_100 < n100_cutoff) %>% pull(sampleID)
  clean_data <- data %>% filter(! sampleID %in% sample_n100_fail) 
  sample_size <- n_distinct(clean_data$sampleID)
  clean_data_info <- sprintf("Step 3 - Sample size after removing samples with less than n100 cutoff = %s, Retained prop. = %s",   sample_size, round(sample_size/n_distinct(data$sampleID), 2))
  
  return(list(clean_data = clean_data, clean_data_info = clean_data_info, removed_sampleID = sample_n100_fail))
}


# Example usage:
result <- remove_n100_cutoff(filtered_data2, n100_cutoff = 0.5)
filtered_data3 <- result$clean_data  # This will give you the data after removing low-loci-coverage samples
print(result$clean_data_info)  # This will print the information of filtered data compared to original input data
sample_n100_fail <- print(result$removed_sampleID) # This will print the information of removed sampleID

```


**Check if there are any loci not amplified well, and if this happened in one sample or many samples**
```{r loci performance check, echo=FALSE, warning = FALSE, message= FALSE}

### Find locus with <= 10 reads
locus_check <- filtered_data3 %>%
  group_by(sampleID, locus) %>%
  summarize(total_reads = sum(reads))

target_low_reads <- locus_check %>% filter(total_reads <= 10) #10 can be changed
gene_low_reads <- merge(target_low_reads, gene, by = "locus")
gene_low_reads %<>% select(sampleID, locus, total_reads, Category, Pool, GeneID, Gene)
gene_low_reads_list <- gene %>% filter(locus %in% unique(gene_low_reads$locus)) %>% group_by(Category)
gene_low_reads_cat <- gene_low_reads_list %>% summarize(n = table(Category))

gene_low_reads_freq <- gene_low_reads %>% pull(locus) %>% vec_count(.) %>% 
  mutate (freq = count/length(unique(filtered_data3$sampleID)))
gene_low_reads_popcut <- gene_low_reads_freq %>% filter(freq > 1/3) 

print(sprintf("%s loci had <= 10 reads at least in one sample", length(unique(gene_low_reads$locus))))
print(sprintf("%s loci had <= 10 reads across 1/3 of total samples", nrow(gene_low_reads_popcut)))
print("Which loci had <= 10 reads across 1/3 of total samples?")
print(gene_low_reads_popcut$key)

```


**qPCR density and sample info**
```{r qPCR density, echo=FALSE, warning = FALSE, message= FALSE}

# Does read coverage correspond to parasite density?

plot_pd_reads <- function(data){ 

# Data
parasitemia <- filtered_data3 %>%
  group_by(sampleID, qPCR_Quantity, Run) %>%
  summarise(total_reads = sum(reads), pass=sum(reads>100), nopass=sum(reads<=100)) %>%
  group_by(sampleID, qPCR_Quantity, Run, total_reads) %>%
  summarize(perc_good = (100*pass/(pass+nopass)))

# Plot
g <- ggplot(data = parasitemia) +
  geom_point(aes(x = log10(qPCR_Quantity), y = log10(total_reads), color = perc_good)) +
  scale_color_gradient(low = "darkred", high = "royalblue", 
                       limits = range(parasitemia$perc_good), name = "% of loci with >100 reads") +
  facet_wrap(~Run) +
  scale_y_log10() +
  ggtitle("Does read coverage correspond to parasite density?") +
  ylab("Log10 total reads") +
  xlab("Parasitemia (log10 p/uL)")

g

}

plot_pd_reads(filtered_data3)

```



**Optional - remove minor alleles**
```{r filter minor alleles - optional, echo=FALSE, warning = FALSE, message= FALSE}

plot_AF_category <- function(data, filter_category = "All"){
  
  # if filter_category is "All"
  if(filter_category == "All") {
    meanAF <- filtered_data3 %>% group_by(allele.type, locus, Category) %>% 
      summarize(host_mean_AF = mean(norm.reads.locus),
                sample_count = n(),
                pop_AF = n()/n_distinct(filtered_data3$sampleID)) 
  } else {
    meanAF <- filtered_data3 %>% filter(Category == filter_category) %>% group_by(allele.type, locus, Category) %>% 
      summarize(host_mean_AF = mean(norm.reads.locus),
                sample_count = n(),
                pop_AF = n()/n_distinct(filtered_data3$sampleID)) 
  }
  
  # Plot population AF with within-host AF - All
  g <- meanAF %>%
    ggplot(aes(x = pop_AF, y = host_mean_AF, alpha = .01, color = "red")) +
    geom_point(aes(size = sample_count)) +
    geom_vline(aes(xintercept = 0.01), linetype = "dashed") +
    geom_hline(aes(yintercept = 0.01), linetype = "dashed") +
    facet_wrap(~ Category)
  
  return(g)
}

ggplotly(plot_AF_category(filtered_data3, filter_category = "All")) #filter_category can be "All", "Diversity", "Diagnostic", "Immune", "Resistance", "Species"
ggplotly(plot_AF_category(filtered_data3, filter_category = "Diversity"))


# Filter minor alleles (within-host & pop AF < 0.01)

remove_minor_allele <- function(data, filter_category = "All", host_AF_cutoff = 0.01, pop_AF_cutoff = 0.01){

# Data
 # if filter_category is "All"
  if(filter_category == "All") {
    meanAF <- filtered_data3 %>% group_by(allele.type, locus, Category) %>% 
      summarize(host_mean_AF = mean(norm.reads.locus),
                sample_count = n(),
                pop_AF = n()/n_distinct(filtered_data3$sampleID)) 
  } else {
    meanAF <- filtered_data3 %>% filter(Category == filter_category) %>% group_by(allele.type, locus, Category) %>% 
      summarize(host_mean_AF = mean(norm.reads.locus),
                sample_count = n(),
                pop_AF = n()/n_distinct(filtered_data3$sampleID)) 
  }

# Filter minor alleles with cutoffs  
minor_count_all <- meanAF %>% filter(host_mean_AF < host_AF_cutoff & pop_AF < pop_AF_cutoff) %>% nrow()
minor_allele_all <- meanAF %>% filter(host_mean_AF < host_AF_cutoff & pop_AF < pop_AF_cutoff) %>% pull (allele.type)

# List after removal
clean_data <- data %>% filter (! allele.type %in% minor_allele_all)
clean_data_info <- print(sprintf("Percentage (x100) of excluded minor alleles in total alleles = %s, Percentage (x100) of excluded minor alleles in total data entries = %s (x100)", round(minor_count_all/nrow(meanAF), 5)*100, round((nrow(data) - nrow(clean_data)) / nrow(data), 5)*100))

return(list(clean_data = clean_data, clean_data_info = clean_data_info, removed_alleles = minor_allele_all))

}


# Example usage:
result <- remove_minor_allele(filtered_data3, filter_category = "All", host_AF_cutoff = 0.01, pop_AF_cutoff = 0.01)
filtered_data4 <- result$clean_data  # This will give you the data after removing minor alleles
print(result$clean_data_info)  # This will print the information of filtered data compared to original input data
removed_alleles <- print(result$removed_alleles) # This will print the information of removed alleles

```


# Make moire input

**Moire input**
```{r moire input, echo=FALSE, warning = FALSE, message= FALSE}

### Filtered data: Remove bad-quality samples only 
moire_data <- filtered_data3 %>% filter (Category == "Diversity") %>% select (sampleID, locus, allele.type)
moire_data %<>% rename("sample_id" = "sampleID", "allele" = "allele.type") 
moire_data %<>% distinct()
write.csv(moire_data, "moire_data_filtered_bad_samples.csv", row.names = F)

### Optional: Remove both bad-quality samples & minor alleles
moire_data1 <- filtered_data4 %>% filter (Category == "Diversity") %>% select (sampleID, locus, allele.type)
moire_data1 %<>% rename("sample_id" = "sampleID", "allele" = "allele.type") 
moire_data1 %<>% distinct()
#write.csv(moire_data1, "moire_data_filtered_bad_samples_and_alleles.csv", row.names = F)

```
